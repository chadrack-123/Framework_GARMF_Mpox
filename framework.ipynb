{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8250f5af-2f9b-4f2f-8d26-fd9ff914ffb7",
   "metadata": {},
   "source": [
    "### Step 1 — Create the project skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d38ba1-30c9-4845-bd11-637eea4292a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Project skeleton\n",
    "import os, pathlib, textwrap, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb075185-3e5d-47de-afca-2b9141a08294",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = pathlib.Path.cwd() / \"mpox_repro_framework\"\n",
    "dirs = [\n",
    "    \"src/cbe_repro/epi\",\n",
    "    \"src/cbe_repro/synth\",\n",
    "    \"src/cbe_repro/eval\",\n",
    "    \"src/cbe_repro/genai\",\n",
    "    \"src/cbe_repro/experiments\",\n",
    "    \"src/cbe_repro/configs\",\n",
    "    \"src/cbe_repro/data\",\n",
    "    \"tests\",\n",
    "    \"docs\",\n",
    "    \"scripts\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6dec8be-c837-4aba-9bbd-5695750538d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make folders\n",
    "for d in dirs:\n",
    "    (ROOT / d).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239c854b-cd1e-4785-9b36-45e98cfce7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Placeholders so imports won’t error later\n",
    "(ROOT / \"src\" / \"cbe_repro\" / \"__init__.py\").write_text(\"__all__ = []\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce43aa1-06ec-4052-a01f-59bfaa2c65f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Basic README + requirements (pin for reproducibility)\n",
    "readme = \"\"\"# Mpox Reproducibility Framework (with GenAI hooks)\n",
    "\n",
    "This repo focuses on **reproducible** mpox modeling:\n",
    "- deterministic outbreak simulations (SEIR),\n",
    "- repeatable ML experiments (fixed seeds),\n",
    "- GenAI hooks for synthetic data (class imbalance) and automated docs,\n",
    "- a simple score to quantify reproducibility.\n",
    "\n",
    "You'll add code in small steps—each step is runnable and testable.\n",
    "\"\"\"\n",
    "\n",
    "(ROOT / \"README.md\").write_text(readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1efdf192-a793-4e15-ba31-c0b21b813fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req = \"\"\"numpy==1.26.4\n",
    "pandas==2.2.2\n",
    "scikit-learn==1.5.2\n",
    "matplotlib==3.8.4\n",
    "pyyaml==6.0.1\n",
    "\"\"\"\n",
    "(ROOT / \"requirements.txt\").write_text(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5beacf1-eaa1-4575-9795-deed4056ff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Tiny “hello world” placeholders for later modules\n",
    "(ROOT / \"src\" / \"cbe_repro\" / \"epi\" / \"seir.py\").write_text(\"def _placeholder():\\n    pass\\n\")\n",
    "(ROOT / \"src\" / \"cbe_repro\" / \"synth\" / \"symptom_smote.py\").write_text(\"def _placeholder():\\n    pass\\n\")\n",
    "(ROOT / \"src\" / \"cbe_repro\" / \"eval\" / \"repro_score.py\").write_text(\"def _placeholder():\\n    pass\\n\")\n",
    "(ROOT / \"src\" / \"cbe_repro\" / \"genai\" / \"codegen.py\").write_text(\"def _placeholder():\\n    pass\\n\")\n",
    "(ROOT / \"src\" / \"cbe_repro\" / \"genai\" / \"docgen.py\").write_text(\"def _placeholder():\\n    pass\\n\")\n",
    "(ROOT / \"src\" / \"cbe_repro\" / \"experiments\" / \"run_experiment.py\").write_text(\"def _placeholder():\\n    pass\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7106d18-00c5-4735-a45f-f0250d3b1bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Minimal configs we’ll fill in later\n",
    "(ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"baseline.yaml\").write_text(\"# to be filled in Step 4–7\\n\")\n",
    "(ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"genai.yaml\").write_text(\"# to be filled in Step 7\\n\")\n",
    "(ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"datasets.yaml\").write_text(\"# to be filled in Step 3\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "771c11ca-c214-401b-b494-94cc8bed962c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Tests/docs/scripts placeholders\n",
    "(ROOT / \"tests\" / \"test_determinism.py\").write_text(\"# to be implemented in Step 8\\n\")\n",
    "(ROOT / \"docs\" / \"README.md\").write_text(\"Auto-generated reports will land here in Step 7.\\n\")\n",
    "(ROOT / \"scripts\" / \"run_baseline.sh\").write_text(\"# to be filled in Step 7\\n\")\n",
    "(ROOT / \"scripts\" / \"run_genai.sh\").write_text(\"# to be filled in Step 7\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74f48254-6b0f-4f9f-bc58-5139ecdcf333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Project skeleton created at: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework\n",
      " - src/cbe_repro/epi\n",
      " - src/cbe_repro/synth\n",
      " - src/cbe_repro/eval\n",
      " - src/cbe_repro/genai\n",
      " - src/cbe_repro/experiments\n",
      " - src/cbe_repro/configs\n",
      " - src/cbe_repro/data\n",
      " - tests\n",
      " - docs\n",
      " - scripts\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Project skeleton created at:\", ROOT.resolve())\n",
    "for d in dirs:\n",
    "    print(\" -\", (ROOT / d).relative_to(ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbba76-6dc9-49b5-9a53-9fd5fba35079",
   "metadata": {},
   "source": [
    "### Step 2 — Create a tiny, reproducible mpox-like symptom dataset + register it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2590cc6-3e34-450d-bb76-977666d06d98",
   "metadata": {},
   "source": [
    "### 2.1 Generate & save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6394159c-830b-4bb6-82a6-7c674215b1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path updated ✅\n"
     ]
    }
   ],
   "source": [
    "# A) Make the package importable in this notebook\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "SRC  = ROOT / \"src\"\n",
    "\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "print(\"sys.path updated ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e272c-256b-447c-89e3-5519703c710e",
   "metadata": {},
   "source": [
    "#### Step 2-Image(A) — Register an image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "387cd3fe-6929-4569-938a-bf859aad9046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_images_raw\n",
      "\n",
      "Subfolders:\n",
      " - non_mpox\n",
      " - mpox\n",
      "\n",
      "Counts:\n",
      "mpox       102 files\n",
      "non_mpox   126 files\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "RAW_DIR = Path.cwd() / \"mpox_images_raw\"  # adjust if your notebook is elsewhere\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "\n",
    "print(\"\\nSubfolders:\")\n",
    "for p in RAW_DIR.iterdir():\n",
    "    if p.is_dir():\n",
    "        print(\" -\", p.name)\n",
    "\n",
    "def count_images(d):\n",
    "    exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\"}\n",
    "    return sum(1 for f in d.glob(\"*\") if f.suffix.lower() in exts)\n",
    "\n",
    "print(\"\\nCounts:\")\n",
    "for cls in [\"mpox\", \"non_mpox\"]:\n",
    "    d = RAW_DIR/cls\n",
    "    print(f\"{cls:10s}\", count_images(d), \"files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed9eb35e-ae7b-4e07-9e11-24c538883f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "##2) Split raw into train/val (80/20) in the framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cba6e9cf-e556-4a03-af42-6bf86e0c1948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully removed /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/data/mpox_images on attempt 1\n",
      "mpox       → train:   81, val:   21\n",
      "non_mpox   → train:  100, val:   26\n",
      "\n",
      "✅ Split complete at: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/data/mpox_images\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, random\n",
    "from pathlib import Path\n",
    "import time # Import time for a small delay\n",
    "\n",
    "# paths\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "TARGET_DIR = ROOT / \"src\" / \"cbe_repro\" / \"data\" / \"mpox_images\"\n",
    "RAW_DIR = Path.cwd() / \"mpox_images_raw\"   # change if needed\n",
    "\n",
    "SPLIT_RATIO = 0.8\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "\n",
    "# --- More robust rmtree function ---\n",
    "def rmtree_robust(path, max_attempts=5, delay_s=0.1):\n",
    "    if not path.exists():\n",
    "        return\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            shutil.rmtree(path)\n",
    "            print(f\"Successfully removed {path} on attempt {attempt + 1}\")\n",
    "            return\n",
    "        except OSError as e:\n",
    "            print(f\"Attempt {attempt + 1} to remove {path} failed: {e}\")\n",
    "            if attempt < max_attempts - 1:\n",
    "                time.sleep(delay_s) # Wait a bit before retrying\n",
    "            else:\n",
    "                raise # Re-raise if all attempts fail\n",
    "\n",
    "# clean + make target dirs\n",
    "if TARGET_DIR.exists():\n",
    "    rmtree_robust(TARGET_DIR) # Use the robust function here\n",
    "for sub in [\"train/mpox\",\"train/non_mpox\",\"val/mpox\",\"val/non_mpox\"]:\n",
    "    (TARGET_DIR / sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def split_class(class_name):\n",
    "    exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\"}\n",
    "    files = [f for f in (RAW_DIR/class_name).glob(\"*\") if f.suffix.lower() in exts]\n",
    "    files.sort()           # deterministic order before shuffling\n",
    "    random.shuffle(files)  # seeded shuffle\n",
    "    n_train = int(len(files)*SPLIT_RATIO)\n",
    "    train_files, val_files = files[:n_train], files[n_train:]\n",
    "    for f in train_files:\n",
    "        shutil.copy(f, TARGET_DIR/\"train\"/class_name/f.name)\n",
    "    for f in val_files:\n",
    "        shutil.copy(f, TARGET_DIR/\"val\"/class_name/f.name)\n",
    "    return len(train_files), len(val_files)\n",
    "\n",
    "for cls in [\"mpox\", \"non_mpox\"]:\n",
    "    tr, va = split_class(cls)\n",
    "    print(f\"{cls:10s} → train: {tr:4d}, val: {va:4d}\")\n",
    "\n",
    "print(\"\\n✅ Split complete at:\", TARGET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98e09ad2-6ebe-4bda-82fd-1afbb256998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3) Register the dataset in datasets.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a788bd1-ce86-417b-b0a7-c674471dce37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated datasets.yaml\n",
      "mpox_images:\n",
      "  root: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/data/mpox_images\n",
      "  splits:\n",
      "    train: train\n",
      "    val: val\n",
      "  classes:\n",
      "    positive: mpox\n",
      "    negative: non_mpox\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "cfg_path = ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"datasets.yaml\"\n",
    "\n",
    "# load existing (robust to empty file)\n",
    "existing_text = cfg_path.read_text() if cfg_path.exists() else \"\"\n",
    "registry = yaml.safe_load(existing_text)\n",
    "if registry is None:\n",
    "    registry = {}\n",
    "\n",
    "# add/replace mpox_images entry\n",
    "registry[\"mpox_images\"] = {\n",
    "    \"root\": str(TARGET_DIR),            # absolute path to the split dataset\n",
    "    \"splits\": {\"train\": \"train\", \"val\": \"val\"},\n",
    "    \"classes\": {\"positive\": \"mpox\", \"negative\": \"non_mpox\"}\n",
    "}\n",
    "\n",
    "cfg_path.write_text(yaml.safe_dump(registry, sort_keys=False))\n",
    "print(\"✅ Updated datasets.yaml\")\n",
    "print(cfg_path.read_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9035c994-c56d-4513-a5c2-f9db0c946241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train / mpox     : 81 images\n",
      "train / non_mpox : 100 images\n",
      "val   / mpox     : 21 images\n",
      "val   / non_mpox : 26 images\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root = TARGET_DIR\n",
    "for split in [\"train\",\"val\"]:\n",
    "    for cls in [\"mpox\",\"non_mpox\"]:\n",
    "        n = sum(1 for f in (root/split/cls).glob(\"*\") if f.suffix.lower() in {\".jpg\",\".jpeg\",\".png\",\".bmp\"})\n",
    "        print(f\"{split:5s} / {cls:9s}: {n} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571251b-c299-4eee-a80c-e13fef133f4f",
   "metadata": {},
   "source": [
    "### Step 2-Image(B) — Add a minimal loader + deterministic augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8519660-06a3-4ab7-a05a-fd12049fee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/synth/image_loader.py\n"
     ]
    }
   ],
   "source": [
    "# Overwrite image_loader.py with ASCII-safe content\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "code_path = ROOT / \"src\" / \"cbe_repro\" / \"synth\" / \"image_loader.py\"\n",
    "\n",
    "code = '''# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "class ImageFolderDataset:\n",
    "    \"\"\"\n",
    "    Minimal, dependency-light loader for mpox lesion images.\n",
    "    - Expects ImageFolder-style structure: root/{split}/{class}/*.jpg\n",
    "    - Deterministic augmentations for reproducible \"GenAI-style\" oversampling\n",
    "    - Simple featurization: downsample + color histograms (works with sklearn)\n",
    "    \"\"\"\n",
    "    def __init__(self, root: str, split: str,\n",
    "                 pos_cls: str = \"mpox\", neg_cls: str = \"non_mpox\",\n",
    "                 seed: int = 1337, img_size: int = 128):\n",
    "        self.root = Path(root)\n",
    "        self.split = split\n",
    "        self.pos_cls = pos_cls\n",
    "        self.neg_cls = neg_cls\n",
    "        self.img_size = img_size\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.samples, self.labels = self._collect()\n",
    "\n",
    "    def _collect(self):\n",
    "        exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "        paths, labels = [], []\n",
    "        for label, cls in [(1, self.pos_cls), (0, self.neg_cls)]:\n",
    "            for p in (self.root / self.split / cls).glob(\"*\"):\n",
    "                if p.suffix.lower() in exts:\n",
    "                    paths.append(p)\n",
    "                    labels.append(label)\n",
    "        return np.array(paths), np.array(labels, dtype=int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    # ---------- I/O + deterministic aug ----------\n",
    "\n",
    "    def _load_image(self, path: Path) -> Image.Image:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = img.resize((self.img_size, self.img_size))\n",
    "        return img\n",
    "\n",
    "    def _deterministic_augment(self, img: Image.Image, idx: int, enable: bool = False) -> Image.Image:\n",
    "        \"\"\"A tiny, deterministic augmentor controlled by sample index.\"\"\"\n",
    "        if not enable:\n",
    "            return img\n",
    "        m = idx % 4\n",
    "        if m == 1:\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        elif m == 2:\n",
    "            img = img.rotate(90, expand=False)\n",
    "        elif m == 3:\n",
    "            img = img.rotate(270, expand=False)\n",
    "        return img\n",
    "\n",
    "    # ---------- simple features ----------\n",
    "\n",
    "    def _simple_features(self, img: Image.Image) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Features = downsampled pixels + 3x16-bin color histograms.\n",
    "        Keeps it light so we can use scikit-learn models deterministically.\n",
    "        \"\"\"\n",
    "        arr = np.asarray(img, dtype=np.float32) / 255.0  # [H,W,3]\n",
    "        # 3 histograms (R/G/B) with 16 bins each\n",
    "        hist_r, _ = np.histogram(arr[:, :, 0], bins=16, range=(0, 1), density=True)\n",
    "        hist_g, _ = np.histogram(arr[:, :, 1], bins=16, range=(0, 1), density=True)\n",
    "        hist_b, _ = np.histogram(arr[:, :, 2], bins=16, range=(0, 1), density=True)\n",
    "        # downsample (32x32x3 if img_size=128) and flatten\n",
    "        flat = arr[::4, ::4, :].reshape(-1)\n",
    "        feats = np.concatenate([flat, hist_r, hist_g, hist_b]).astype(np.float32)\n",
    "        return feats\n",
    "\n",
    "    # ---------- public API ----------\n",
    "\n",
    "    def as_features_labels(self, synth_enabled: bool = False, synth_multiplier: float = 1.0):\n",
    "        \"\"\"\n",
    "        Returns (X, y).\n",
    "        If synth_enabled and multiplier>1, oversamples positives deterministically\n",
    "        using the augmentor to diversify the added copies.\n",
    "        \"\"\"\n",
    "        # base features\n",
    "        X, y = [], []\n",
    "        for i, p in enumerate(self.samples):\n",
    "            img = self._load_image(p)\n",
    "            img = self._deterministic_augment(img, i, enable=False)  # no aug on base\n",
    "            X.append(self._simple_features(img))\n",
    "            y.append(self.labels[i])\n",
    "        X = np.vstack(X).astype(np.float32)\n",
    "        y = np.array(y, dtype=int)\n",
    "\n",
    "        # deterministic oversample of positives if requested\n",
    "        if synth_enabled and synth_multiplier > 1.0:\n",
    "            pos_idx = np.where(y == 1)[0]\n",
    "            if len(pos_idx) > 0:\n",
    "                target = int(len(pos_idx) * synth_multiplier)\n",
    "                extra = target - len(pos_idx)\n",
    "                if extra > 0:\n",
    "                    rep = (extra + len(pos_idx) - 1) // len(pos_idx)\n",
    "                    aug_idx = np.tile(pos_idx, rep)[:extra]\n",
    "                    X_aug = []\n",
    "                    for k, idx in enumerate(aug_idx):\n",
    "                        img = self._load_image(self.samples[idx])\n",
    "                        img = self._deterministic_augment(img, k, enable=True)\n",
    "                        X_aug.append(self._simple_features(img))\n",
    "                    if X_aug:\n",
    "                        X = np.vstack([X, np.vstack(X_aug).astype(np.float32)])\n",
    "                        y = np.concatenate([y, np.ones(len(X_aug), dtype=int)])\n",
    "        return X, y\n",
    "'''\n",
    "code_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "code_path.write_text(code, encoding=\"utf-8\")\n",
    "print(\"Rewrote:\", code_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f67c7b3-a953-4d79-b376-9e817be0cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared __pycache__ (if existed).\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "pycache = (Path.cwd() / \"mpox_repro_framework\" / \"src\" / \"cbe_repro\" / \"__pycache__\")\n",
    "shutil.rmtree(pycache, ignore_errors=True)\n",
    "print(\"Cleared __pycache__ (if existed).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd71a681-8458-4b8b-bddf-7d4aa3fd5933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported ImageFolderDataset ✅\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "SRC  = ROOT / \"src\"\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "from cbe_repro.synth.image_loader import ImageFolderDataset\n",
    "print(\"Imported ImageFolderDataset ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84b3840b-4d65-4d5e-a99f-d95dd3d985c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (181, 3120) Label counts: Counter({np.int64(0): 100, np.int64(1): 81})\n",
      "Val   features: (47, 3120) Label counts: Counter({np.int64(0): 26, np.int64(1): 21})\n",
      "Train (synth x3): (343, 3120) Label counts: Counter({np.int64(1): 243, np.int64(0): 100})\n"
     ]
    }
   ],
   "source": [
    "# STEP 2-Image(B).2: Smoke test the loader on your split dataset\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from collections import Counter\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "cfg_path = ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"datasets.yaml\"\n",
    "\n",
    "# read registry\n",
    "reg = yaml.safe_load(cfg_path.read_text())\n",
    "entry = reg[\"mpox_images\"]\n",
    "root = entry[\"root\"]\n",
    "pos = entry[\"classes\"][\"positive\"]\n",
    "neg = entry[\"classes\"][\"negative\"]\n",
    "splits = entry[\"splits\"]\n",
    "\n",
    "# import the loader we wrote\n",
    "from cbe_repro.synth.image_loader import ImageFolderDataset\n",
    "\n",
    "SEED = 1337\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# train and val datasets\n",
    "train_ds = ImageFolderDataset(root, splits[\"train\"], pos_cls=pos, neg_cls=neg, seed=SEED, img_size=IMG_SIZE)\n",
    "val_ds   = ImageFolderDataset(root, splits[\"val\"],   pos_cls=pos, neg_cls=neg, seed=SEED, img_size=IMG_SIZE)\n",
    "\n",
    "# extract features\n",
    "Xtr, ytr = train_ds.as_features_labels(synth_enabled=False)\n",
    "Xva, yva = val_ds.as_features_labels(synth_enabled=False)\n",
    "\n",
    "print(\"Train features:\", Xtr.shape, \"Label counts:\", Counter(ytr))\n",
    "print(\"Val   features:\", Xva.shape, \"Label counts:\", Counter(yva))\n",
    "\n",
    "# test GenAI-style oversampling (triple positives)\n",
    "Xtr_gen, ytr_gen = train_ds.as_features_labels(synth_enabled=True, synth_multiplier=3.0)\n",
    "print(\"Train (synth x3):\", Xtr_gen.shape, \"Label counts:\", Counter(ytr_gen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6c18092-53d9-4a5b-9193-7abb875eafdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package dir: True /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro\n",
      "Loader file: True /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/synth/image_loader.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "pkg = ROOT / \"src\" / \"cbe_repro\"\n",
    "loader_file = pkg / \"synth\" / \"image_loader.py\"\n",
    "\n",
    "# create __init__.py if it doesn't exist\n",
    "(pkg).mkdir(parents=True, exist_ok=True)\n",
    "(pkg / \"__init__.py\").write_text(\"__all__ = []\\n\") if not (pkg / \"__init__.py\").exists() else None\n",
    "\n",
    "print(\"Package dir:\", pkg.exists(), pkg)\n",
    "print(\"Loader file:\", loader_file.exists(), loader_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9766019-6a81-4327-9fcd-dcda7e368b2b",
   "metadata": {},
   "source": [
    "### Step 2-Image(C) — Add a tiny imaging experiment runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a9fa9c5-00eb-4ec6-bbbd-de020ae6a3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/run_imaging.py\n"
     ]
    }
   ],
   "source": [
    "# STEP 2-Image(C).1: Write imaging experiment runner\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "runner_path = ROOT / \"src\" / \"cbe_repro\" / \"experiments\" / \"run_imaging.py\"\n",
    "\n",
    "code = '''# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "import json, time, pathlib, yaml, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from cbe_repro.synth.image_loader import ImageFolderDataset\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def load_cfg(name: str):\n",
    "    cfg_dir = pathlib.Path(__file__).resolve().parents[1] / \"configs\"\n",
    "    with open(cfg_dir / name, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def _load_dataset_entry(reg_name: str):\n",
    "    cfg_dir = pathlib.Path(__file__).resolve().parents[1] / \"configs\"\n",
    "    with open(cfg_dir / \"datasets.yaml\",\"r\") as f:\n",
    "        reg = yaml.safe_load(f)\n",
    "    return reg[reg_name]\n",
    "\n",
    "def main(config_name=\"imaging_baseline.yaml\"):\n",
    "    cfg = load_cfg(config_name)\n",
    "    seed = int(cfg.get(\"seed\", 1337))\n",
    "    set_seed(seed)\n",
    "\n",
    "    ds_reg = _load_dataset_entry(cfg[\"dataset\"])\n",
    "    root = ds_reg[\"root\"]\n",
    "    pos = ds_reg[\"classes\"][\"positive\"]\n",
    "    neg = ds_reg[\"classes\"][\"negative\"]\n",
    "    splits = ds_reg[\"splits\"]\n",
    "\n",
    "    # Train features (optionally with deterministic oversampling)\n",
    "    train_ds = ImageFolderDataset(root, splits[\"train\"], pos_cls=pos, neg_cls=neg,\n",
    "                                  seed=seed, img_size=cfg[\"image_size\"])\n",
    "    X_tr, y_tr = train_ds.as_features_labels(\n",
    "        synth_enabled=cfg.get(\"synth\",{}).get(\"enabled\", False),\n",
    "        synth_multiplier=float(cfg.get(\"synth\",{}).get(\"minority_multiplier\", 1.0))\n",
    "    )\n",
    "\n",
    "    # Validation features (clean)\n",
    "    val_ds = ImageFolderDataset(root, splits[\"val\"], pos_cls=pos, neg_cls=neg,\n",
    "                                seed=seed, img_size=cfg[\"image_size\"])\n",
    "    X_va, y_va = val_ds.as_features_labels(synth_enabled=False)\n",
    "\n",
    "    # Simple, deterministic classifier\n",
    "    model = LogisticRegression(max_iter=300, **cfg.get(\"model\",{}).get(\"params\", {}))\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_va)\n",
    "\n",
    "    acc = float(accuracy_score(y_va, y_pred))\n",
    "    f1  = float(f1_score(y_va, y_pred))\n",
    "\n",
    "    manifest = {\n",
    "        \"run_id\": str(int(time.time())),\n",
    "        \"started\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"config_name\": config_name,\n",
    "        \"metrics\": {\"acc\": acc, \"f1\": f1},\n",
    "        \"notes\": f\"imaging pipeline; synth={cfg.get('synth',{}).get('enabled', False)}; img_size={cfg['image_size']}\"\n",
    "    }\n",
    "    out_dir = pathlib.Path.cwd() / \"runs\" / manifest[\"run_id\"]\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (out_dir / \"manifest.json\").write_text(json.dumps(manifest, indent=2))\n",
    "    print(json.dumps(manifest, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--config-name\", default=\"imaging_baseline.yaml\")\n",
    "    args = ap.parse_args()\n",
    "    main(config_name=args.config_name)\n",
    "'''\n",
    "runner_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "runner_path.write_text(code, encoding=\"utf-8\")\n",
    "print(\"✅ Wrote:\", runner_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e06f2-1c11-473a-8ec4-f589993c3b7d",
   "metadata": {},
   "source": [
    "### Add two configs: baseline vs GenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "896b5530-c82b-4d71-a957-59936a863fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/imaging_baseline.yaml\n",
      "✅ Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/imaging_genai.yaml\n"
     ]
    }
   ],
   "source": [
    "# STEP 2-Image(C).2: Write imaging configs\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "cfg_dir = ROOT / \"src\" / \"cbe_repro\" / \"configs\"\n",
    "cfg_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "imaging_baseline = {\n",
    "    \"seed\": 1337,\n",
    "    \"dataset\": \"mpox_images\",\n",
    "    \"task\": \"imaging_classification\",\n",
    "    \"image_size\": 128,\n",
    "    \"model\": {\"name\": \"LogisticRegression\", \"params\": {\"C\": 1.0}},\n",
    "    \"synth\": {\"enabled\": False, \"minority_multiplier\": 1.0}\n",
    "}\n",
    "\n",
    "imaging_genai = {\n",
    "    \"seed\": 1337,\n",
    "    \"dataset\": \"mpox_images\",\n",
    "    \"task\": \"imaging_classification\",\n",
    "    \"image_size\": 128,\n",
    "    \"model\": {\"name\": \"LogisticRegression\", \"params\": {\"C\": 1.0}},\n",
    "    \"synth\": {\"enabled\": True, \"minority_multiplier\": 3.0}  # deterministically oversample positives\n",
    "}\n",
    "\n",
    "(cfg_dir / \"imaging_baseline.yaml\").write_text(yaml.safe_dump(imaging_baseline, sort_keys=False))\n",
    "(cfg_dir / \"imaging_genai.yaml\").write_text(yaml.safe_dump(imaging_genai, sort_keys=False))\n",
    "\n",
    "print(\"✅ Wrote:\", cfg_dir / \"imaging_baseline.yaml\")\n",
    "print(\"✅ Wrote:\", cfg_dir / \"imaging_genai.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13319e00-15c0-4dfb-9561-25be319a1782",
   "metadata": {},
   "source": [
    "### Run both experiments and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f38cff05-6386-43c0-bab8-b6c70c214ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== imaging_baseline.yaml ===\n",
      "Return code: 0\n",
      "-- STDOUT --\n",
      " {\n",
      "  \"run_id\": \"1756981262\",\n",
      "  \"started\": \"2025-09-04 12:21:02\",\n",
      "  \"config_name\": \"imaging_baseline.yaml\",\n",
      "  \"metrics\": {\n",
      "    \"acc\": 0.5957446808510638,\n",
      "    \"f1\": 0.5777777777777777\n",
      "  },\n",
      "  \"notes\": \"imaging pipeline; synth=False; img_size=128\"\n",
      "}\n",
      "\n",
      "\n",
      "=== imaging_genai.yaml ===\n",
      "Return code: 0\n",
      "-- STDOUT --\n",
      " {\n",
      "  \"run_id\": \"1756981264\",\n",
      "  \"started\": \"2025-09-04 12:21:04\",\n",
      "  \"config_name\": \"imaging_genai.yaml\",\n",
      "  \"metrics\": {\n",
      "    \"acc\": 0.574468085106383,\n",
      "    \"f1\": 0.6\n",
      "  },\n",
      "  \"notes\": \"imaging pipeline; synth=True; img_size=128\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run imaging experiments with PYTHONPATH pointing at ./src\n",
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "SRC  = ROOT / \"src\"\n",
    "\n",
    "env = os.environ.copy()\n",
    "env[\"PYTHONPATH\"] = str(SRC) + os.pathsep + env.get(\"PYTHONPATH\", \"\")\n",
    "\n",
    "def run_cfg(cfg_name):\n",
    "    print(f\"\\n=== {cfg_name} ===\")\n",
    "    p = subprocess.run(\n",
    "        [sys.executable, \"-m\", \"cbe_repro.experiments.run_imaging\", \"--config-name\", cfg_name],\n",
    "        cwd=ROOT,\n",
    "        env=env,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    print(\"Return code:\", p.returncode)\n",
    "    if p.stdout: print(\"-- STDOUT --\\n\", p.stdout)\n",
    "    if p.stderr: print(\"-- STDERR --\\n\", p.stderr)\n",
    "\n",
    "run_cfg(\"imaging_baseline.yaml\")\n",
    "run_cfg(\"imaging_genai.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a250e-ffc6-4574-ac50-a3e4f560677c",
   "metadata": {},
   "source": [
    "### Tabular loader & experiment runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b659404-6bc6-4dec-8ec2-a082442357fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/data/symptom_demo.csv\n",
      "✅ Updated datasets.yaml:\n",
      " mpox_images:\n",
      "  root: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/data/mpox_images\n",
      "  splits:\n",
      "    train: train\n",
      "    val: val\n",
      "  classes:\n",
      "    positive: mpox\n",
      "    negative: non_mpox\n",
      "symptom_demo:\n",
      "  path: data/symptom_demo.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create tiny symptom dataset + ensure datasets.yaml has BOTH entries\n",
    "import numpy as np, pandas as pd, yaml\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "DATA_DIR = ROOT / \"src\" / \"cbe_repro\" / \"data\"\n",
    "CFG_PATH = ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"datasets.yaml\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "csv_path = DATA_DIR / \"symptom_demo.csv\"\n",
    "\n",
    "# 1A) Make the dataset if missing\n",
    "if not csv_path.exists():\n",
    "    rng = np.random.default_rng(1337)\n",
    "    def synth_symptom(n: int, label: int, rng):\n",
    "        p = {\n",
    "            1: dict(fever=0.65, rash=0.70, lymph=0.55, headache=0.45, age_mu=32, age_sd=8),\n",
    "            0: dict(fever=0.20, rash=0.10, lymph=0.15, headache=0.25, age_mu=29, age_sd=8),\n",
    "        }[label]\n",
    "        return pd.DataFrame({\n",
    "            \"fever\":    rng.binomial(1, p[\"fever\"],    n),\n",
    "            \"rash\":     rng.binomial(1, p[\"rash\"],     n),\n",
    "            \"lymph\":    rng.binomial(1, p[\"lymph\"],    n),\n",
    "            \"headache\": rng.binomial(1, p[\"headache\"], n),\n",
    "            \"age\":      rng.normal(p[\"age_mu\"], p[\"age_sd\"], n).clip(0, 90),\n",
    "            \"label\":    label\n",
    "        })\n",
    "    df = pd.concat([synth_symptom(40, 1, rng), synth_symptom(160, 0, rng)], ignore_index=True)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(\"✅ Wrote dataset:\", csv_path)\n",
    "else:\n",
    "    print(\"Dataset already exists:\", csv_path)\n",
    "\n",
    "# 1B) Merge/update datasets.yaml\n",
    "existing = yaml.safe_load(CFG_PATH.read_text()) if CFG_PATH.exists() else {}\n",
    "if existing is None:\n",
    "    existing = {}\n",
    "\n",
    "# preserve any existing mpox_images entry\n",
    "mpox_images_entry = existing.get(\"mpox_images\")\n",
    "\n",
    "# add/update symptom_demo entry\n",
    "existing[\"symptom_demo\"] = {\n",
    "    \"path\": \"data/symptom_demo.csv\"  # the runner reads from src/cbe_repro/data/<basename>\n",
    "}\n",
    "\n",
    "# restore mpox_images if it was present\n",
    "if mpox_images_entry:\n",
    "    existing[\"mpox_images\"] = mpox_images_entry\n",
    "\n",
    "CFG_PATH.write_text(yaml.safe_dump(existing, sort_keys=False))\n",
    "print(\"✅ Updated datasets.yaml:\\n\", CFG_PATH.read_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4b45e-be78-486a-9354-c75dc4666a94",
   "metadata": {},
   "source": [
    "#### 3.1 Loader + synthetic augmentation (SMOTE/oversample fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e0a66c9-c7df-465d-9254-4c17c0e962ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/synth/symptom_smote.py\n"
     ]
    }
   ],
   "source": [
    "# src/cbe_repro/synth/symptom_smote.py\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "code_path = ROOT / \"src\" / \"cbe_repro\" / \"synth\" / \"symptom_smote.py\"\n",
    "\n",
    "code = '''# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def _counts(y: pd.Series):\n",
    "    # returns dict {label: count}\n",
    "    vals, cnts = np.unique(y, return_counts=True)\n",
    "    return dict(zip(vals, cnts))\n",
    "\n",
    "def simple_random_oversample_any_minority(\n",
    "    X: pd.DataFrame, y: pd.Series, target_ratio: float = 1.0, seed: int = 1337\n",
    "):\n",
    "    \"\"\"\n",
    "    Randomly oversample the true minority class(es) until:\n",
    "      minority_count ≈ target_ratio * majority_count\n",
    "    target_ratio=1.0 -> full balance (equal counts).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    counts = _counts(y)\n",
    "    if len(counts) <= 1:\n",
    "        return X, y  # nothing to balance\n",
    "\n",
    "    # identify majority and minority labels\n",
    "    maj_label = max(counts, key=counts.get)\n",
    "    maj_n = counts[maj_label]\n",
    "    target_min_n = int(np.ceil(target_ratio * maj_n))\n",
    "\n",
    "    X_aug, y_aug = X.copy(), y.copy()\n",
    "    for lbl, n in counts.items():\n",
    "        if lbl == maj_label:\n",
    "            continue\n",
    "        if n >= target_min_n:\n",
    "            continue  # already at/above target\n",
    "        need = target_min_n - n\n",
    "        idx = np.where(y == lbl)[0]\n",
    "        sampled = rng.choice(idx, size=need, replace=True)\n",
    "        X_aug = pd.concat([X_aug, X.iloc[sampled]], ignore_index=True)\n",
    "        y_aug = pd.concat([y_aug, y.iloc[sampled]], ignore_index=True)\n",
    "\n",
    "    return X_aug, y_aug\n",
    "\n",
    "def smote_or_oversample(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    multiplier: float = 2.0,        # kept for backward-compat\n",
    "    seed: int = 1337,\n",
    "    balance_to_max: bool = False,   # NEW: if True, ignore multiplier and fully balance\n",
    "    target_ratio: float | None = None  # NEW: minority/majority ratio; 1.0 == full balance\n",
    "):\n",
    "    \"\"\"\n",
    "    If balance_to_max=True -> fully balance (minority up to majority).\n",
    "    Else if target_ratio is given -> minority up to target_ratio * majority.\n",
    "    Else fallback to legacy 'multiplier' for *positive-class* only (y==1).\n",
    "    \"\"\"\n",
    "    # Decide strategy\n",
    "    if balance_to_max or (target_ratio is not None):\n",
    "        ratio = 1.0 if balance_to_max else float(target_ratio)\n",
    "        try:\n",
    "            from imblearn.over_sampling import SMOTE\n",
    "            counts = _counts(y)\n",
    "            if len(counts) <= 1:\n",
    "                return X, y\n",
    "\n",
    "            # Build sampling_strategy dict: for every minority class, desired count\n",
    "            maj_n = max(counts.values())\n",
    "            desired = {lbl: max(n, int(np.ceil(ratio * maj_n)))\n",
    "                       for lbl, n in counts.items()}\n",
    "            # imblearn expects only minority targets in dict; remove majority if equal\n",
    "            maj_label = max(counts, key=counts.get)\n",
    "            if desired.get(maj_label, maj_n) == maj_n:\n",
    "                desired.pop(maj_label, None)\n",
    "\n",
    "            if not desired:\n",
    "                return X, y  # already balanced to desired ratio\n",
    "\n",
    "            # k_neighbors must be < minority count; pick safely\n",
    "            min_minority_n = min(n for lbl, n in counts.items() if lbl != maj_label)\n",
    "            k = max(1, min(5, min_minority_n - 1))\n",
    "            sm = SMOTE(random_state=seed, k_neighbors=k, sampling_strategy=desired)\n",
    "            X_res, y_res = sm.fit_resample(X, y)\n",
    "            print(f\"[DEBUG] SMOTE balance → before={counts} after={_counts(y_res)} target_ratio={ratio}\")\n",
    "            # Return as pandas\n",
    "            return (pd.DataFrame(X_res, columns=X.columns)\n",
    "                    if not isinstance(X, pd.DataFrame) else X_res, \n",
    "                    pd.Series(y_res) if not isinstance(y, pd.Series) else y_res)\n",
    "        except Exception as e:\n",
    "            print(f\"[DEBUG] SMOTE unavailable ({e}); falling back to random oversample\")\n",
    "            X2, y2 = simple_random_oversample_any_minority(X, y, target_ratio=ratio, seed=seed)\n",
    "            print(f\"[DEBUG] Random balance → before={_counts(y)} after={_counts(y2)} target_ratio={ratio}\")\n",
    "            return X2, y2\n",
    "\n",
    "    # -------- Legacy path (kept so your old profiles still run) --------\n",
    "    # Only oversamples the positive class (1) by 'multiplier' — not class-aware.\n",
    "    # Prefer the balanced modes above for real class balancing.\n",
    "    try:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        pos_n = int((y == 1).sum()); neg_n = int((y == 0).sum())\n",
    "        k = max(1, min(5, pos_n - 1))\n",
    "        sm = SMOTE(random_state=seed, k_neighbors=k)\n",
    "        X_res, y_res = sm.fit_resample(X, y)\n",
    "        target_pos = int(multiplier * pos_n)\n",
    "        cur_pos = int((y_res == 1).sum())\n",
    "        if target_pos > cur_pos:\n",
    "            more = target_pos - cur_pos\n",
    "            pos_idx = np.where(y_res == 1)[0]\n",
    "            rng = np.random.default_rng(seed)\n",
    "            sampled = rng.choice(pos_idx, size=more, replace=True)\n",
    "            X_res = pd.concat(\n",
    "                [pd.DataFrame(X_res, columns=X.columns),\n",
    "                 pd.DataFrame(X_res[sampled], columns=X.columns)],\n",
    "                ignore_index=True\n",
    "            )\n",
    "            y_res = pd.concat([pd.Series(y_res), pd.Series(y_res[sampled])], ignore_index=True)\n",
    "        print(f\"[DEBUG] Legacy synth → before=[{neg_n} {pos_n}] after={_counts(y_res)} multiplier={multiplier}\")\n",
    "        return X_res, y_res\n",
    "    except Exception:\n",
    "        # simple positive-only oversample\n",
    "        rng = np.random.default_rng(seed)\n",
    "        pos_idx = np.where(y == 1)[0]\n",
    "        if len(pos_idx) == 0 or multiplier <= 1.0:  # nothing to do\n",
    "            return X, y\n",
    "        n_new = int((multiplier - 1.0) * len(pos_idx))\n",
    "        sampled = rng.choice(pos_idx, size=n_new, replace=True)\n",
    "        X_aug = pd.concat([X, X.iloc[sampled]], ignore_index=True)\n",
    "        y_aug = pd.concat([y, y.iloc[sampled]], ignore_index=True)\n",
    "        print(f\"[DEBUG] Legacy random → before={_counts(y)} after={_counts(y_aug)} multiplier={multiplier}\")\n",
    "        return X_aug, y_aug\n",
    "\n",
    "'''\n",
    "code_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "code_path.write_text(code, encoding=\"utf-8\")\n",
    "print(\"✅ Wrote:\", code_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7d27fb-a6ec-4a22-aa31-ddace4ece026",
   "metadata": {},
   "source": [
    "#### Tabular experiment runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d21726e-6d0f-4a0e-b9f2-b2f9e52ec8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/run_tabular.py\n"
     ]
    }
   ],
   "source": [
    "# src/cbe_repro/experiments/run_tabular.py\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "runner_path = ROOT / \"src\" / \"cbe_repro\" / \"experiments\" / \"run_tabular.py\"\n",
    "\n",
    "code = '''# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def _as_df(X):\n",
    "    # Ensure we keep column names after imblearn returns numpy arrays\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        return X\n",
    "    raise TypeError(\"X must be a pandas DataFrame\")\n",
    "\n",
    "def _as_sr(y):\n",
    "    if isinstance(y, pd.Series):\n",
    "        return y\n",
    "    raise TypeError(\"y must be a pandas Series\")\n",
    "\n",
    "def simple_random_oversample(X: pd.DataFrame, y: pd.Series, target_min_count: int, seed: int=1337):\n",
    "    \"\"\"Randomly oversample the current minority class up to target_min_count.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = _as_df(X); y = _as_sr(y)\n",
    "\n",
    "    # Identify classes\n",
    "    vc = y.value_counts()\n",
    "    minority_label = vc.idxmin()\n",
    "    minority_idx = np.where(y.values == minority_label)[0]\n",
    "\n",
    "    need = int(target_min_count) - len(minority_idx)\n",
    "    if need <= 0:\n",
    "        return X, y\n",
    "\n",
    "    sampled = rng.choice(minority_idx, size=need, replace=True)\n",
    "    X_aug = pd.concat([X, X.iloc[sampled]], ignore_index=True)\n",
    "    y_aug = pd.concat([y, y.iloc[sampled]], ignore_index=True)\n",
    "    return X_aug, y_aug\n",
    "\n",
    "def smote_or_oversample(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    multiplier: float = 2.0,\n",
    "    seed: int = 1337,\n",
    "    *,\n",
    "    balance_to_max: bool = False,\n",
    "    target_ratio: float | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Oversample the minority class using SMOTE when available; else simple random oversampling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    multiplier : float\n",
    "        If neither balance_to_max nor target_ratio is set, grow the minority count by this factor.\n",
    "        e.g., 2.0 doubles the minority count.\n",
    "    balance_to_max : bool\n",
    "        If True, make the minority count equal to the majority count (full balance).\n",
    "    target_ratio : float | None\n",
    "        Desired minority/majority ratio (e.g., 0.7 -> minority will be 70% of majority size).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Minority class is detected automatically from y’s value_counts().\n",
    "    - Works when the *positive* class is the majority as well (we just balance the minority).\n",
    "    \"\"\"\n",
    "    X = _as_df(X); y = _as_sr(y)\n",
    "\n",
    "    vc = y.value_counts()\n",
    "    if len(vc) < 2:\n",
    "        # Nothing to resample if only one class\n",
    "        return X, y\n",
    "\n",
    "    # Identify minority/majority\n",
    "    minority_label = vc.idxmin()\n",
    "    majority_label = vc.idxmax()\n",
    "    n_min = int(vc.loc[minority_label])\n",
    "    n_maj = int(vc.loc[majority_label])\n",
    "\n",
    "    # Decide target minority count\n",
    "    if balance_to_max:\n",
    "        target_min = n_maj\n",
    "    elif target_ratio is not None:\n",
    "        target_min = int(round(target_ratio * n_maj))\n",
    "    else:\n",
    "        target_min = int(round(multiplier * n_min))\n",
    "\n",
    "    # No need to upsample if target not larger than current minority\n",
    "    if target_min <= n_min:\n",
    "        return X, y\n",
    "\n",
    "    # Try SMOTE first\n",
    "    try:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        # sampling_strategy expects the *final* minority count\n",
    "        sampling_strategy = {minority_label: target_min}\n",
    "        k = min(5, max(1, n_min - 1))\n",
    "        sm = SMOTE(random_state=seed, k_neighbors=k, sampling_strategy=sampling_strategy)\n",
    "        X_res, y_res = sm.fit_resample(X, y)\n",
    "        # Keep as DataFrame/Series with original column names\n",
    "        X_res = pd.DataFrame(X_res, columns=X.columns)\n",
    "        y_res = pd.Series(y_res, name=y.name)\n",
    "        return X_res, y_res\n",
    "    except Exception:\n",
    "        # Fallback: random oversample to target_min\n",
    "        return simple_random_oversample(X, y, target_min_count=target_min, seed=seed)\n",
    "\n",
    "'''\n",
    "runner_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "runner_path.write_text(code, encoding=\"utf-8\")\n",
    "print(\"✅ Wrote:\", runner_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec52e5d-a54c-42e8-8ebe-879361f1bde1",
   "metadata": {},
   "source": [
    "#### Tabular configs (baseline vs GenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e98be28-bf44-4db2-a181-ffaff14b7bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/tabular_baseline.yaml\n",
      "✅ Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/tabular_genai.yaml\n"
     ]
    }
   ],
   "source": [
    "# src/cbe_repro/configs/tabular_baseline.yaml & tabular_genai.yaml\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*_validate_data.*\", category=FutureWarning)\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "cfg_dir = ROOT / \"src\" / \"cbe_repro\" / \"configs\"\n",
    "\n",
    "tabular_baseline = {\n",
    "    \"seed\": 1337,\n",
    "    \"dataset\": \"symptom_demo\",   # was registered earlier\n",
    "    \"task\": \"symptom_classification\",\n",
    "    \"model\": {\"name\": \"RandomForestClassifier\", \"params\": {\"n_estimators\": 200, \"max_depth\": 6, \"random_state\": 1337}},\n",
    "    \"synth\": {\"enabled\": False, \"minority_multiplier\": 1.0}\n",
    "}\n",
    "\n",
    "tabular_genai = {\n",
    "    \"seed\": 1337,\n",
    "    \"dataset\": \"symptom_demo\",\n",
    "    \"task\": \"symptom_classification\",\n",
    "    \"model\": {\"name\": \"RandomForestClassifier\", \"params\": {\"n_estimators\": 300, \"max_depth\": 8, \"random_state\": 1337, \"class_weight\": \"balanced\" }},\n",
    "    \"synth\": {\"enabled\": True, \"minority_multiplier\": 2.0}\n",
    "}\n",
    "\n",
    "(cfg_dir / \"tabular_baseline.yaml\").write_text(yaml.safe_dump(tabular_baseline, sort_keys=False))\n",
    "(cfg_dir / \"tabular_genai.yaml\").write_text(yaml.safe_dump(tabular_genai, sort_keys=False))\n",
    "\n",
    "print(\"✅ Wrote:\", cfg_dir / \"tabular_baseline.yaml\")\n",
    "print(\"✅ Wrote:\", cfg_dir / \"tabular_genai.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bae81-24cf-4175-b5ad-ebed17e63989",
   "metadata": {},
   "source": [
    "#### Run tabular experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d8801da-9ee8-437a-9931-cd962d028879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registry keys: ['mpox_images', 'symptom_demo']\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "CFG_PATH = Path.cwd() / \"mpox_repro_framework\" / \"src\" / \"cbe_repro\" / \"configs\" / \"datasets.yaml\"\n",
    "reg = yaml.safe_load(CFG_PATH.read_text())\n",
    "print(\"Registry keys:\", list(reg.keys()))\n",
    "assert \"symptom_demo\" in reg, \"symptom_demo not found in datasets.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4386d61-01c1-4af9-ab7c-18264e7dd8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== tabular_baseline.yaml ===\n",
      "Return code: 0\n",
      "\n",
      "=== tabular_genai.yaml ===\n",
      "Return code: 0\n"
     ]
    }
   ],
   "source": [
    "# Run tabular baseline & genai with PYTHONPATH\n",
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "SRC  = ROOT / \"src\"\n",
    "\n",
    "env = os.environ.copy()\n",
    "env[\"PYTHONPATH\"] = str(SRC) + os.pathsep + env.get(\"PYTHONPATH\", \"\")\n",
    "\n",
    "def run_cfg(cfg_name):\n",
    "    print(f\"\\n=== {cfg_name} ===\")\n",
    "    p = subprocess.run(\n",
    "        [sys.executable, \"-m\", \"cbe_repro.experiments.run_tabular\", \"--config-name\", cfg_name],\n",
    "        cwd=ROOT,\n",
    "        env=env,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    print(\"Return code:\", p.returncode)\n",
    "    if p.stdout: print(\"-- STDOUT --\\n\", p.stdout)\n",
    "    if p.stderr: print(\"-- STDERR --\\n\", p.stderr)\n",
    "\n",
    "run_cfg(\"tabular_baseline.yaml\")\n",
    "run_cfg(\"tabular_genai.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d656cc90-eba8-4fee-ab5a-0abeccbddc9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'config_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mf\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     12\u001b[0m         j \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(mf\u001b[38;5;241m.\u001b[39mread_text())\n\u001b[1;32m     13\u001b[0m         rows\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m---> 14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: j[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_name\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m: j[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     16\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: j[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m\"\u001b[39m: j[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: j[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m         })\n\u001b[1;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\n\u001b[1;32m     22\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'config_name'"
     ]
    }
   ],
   "source": [
    "# # Build comparison across imaging + tabular and save to CSV/Markdown\n",
    "# import json, pandas as pd\n",
    "# from pathlib import Path\n",
    "\n",
    "# ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "# RUNS = ROOT / \"runs\"\n",
    "\n",
    "# rows = []\n",
    "# for d in RUNS.glob(\"*\"):\n",
    "#     mf = d / \"manifest.json\"\n",
    "#     if mf.exists():\n",
    "#         j = json.loads(mf.read_text())\n",
    "#         rows.append({\n",
    "#             \"config\": j[\"config_name\"],\n",
    "#             \"acc\": j[\"metrics\"][\"acc\"],\n",
    "#             \"f1\": j[\"metrics\"][\"f1\"],\n",
    "#             \"started\": j[\"started\"],\n",
    "#             \"run_id\": j[\"run_id\"]\n",
    "#         })\n",
    "\n",
    "# df = pd.DataFrame(rows)\n",
    "# df = df.sort_values(\"started\").groupby(\"config\", as_index=False).tail(1).reset_index(drop=True)\n",
    "\n",
    "# def pair(stem):\n",
    "#     base = df[df[\"config\"]==f\"{stem}_baseline.yaml\"]\n",
    "#     gen  = df[df[\"config\"]==f\"{stem}_genai.yaml\"]\n",
    "#     if base.empty or gen.empty: return None\n",
    "#     return {\n",
    "#         \"task\": stem,\n",
    "#         \"baseline_acc\": float(base[\"acc\"].iloc[0]),\n",
    "#         \"genai_acc\": float(gen[\"acc\"].iloc[0]),\n",
    "#         \"delta_acc\": float(gen[\"acc\"].iloc[0]) - float(base[\"acc\"].iloc[0]),\n",
    "#         \"baseline_f1\": float(base[\"f1\"].iloc[0]),\n",
    "#         \"genai_f1\": float(gen[\"f1\"].iloc[0]),\n",
    "#         \"delta_f1\": float(gen[\"f1\"].iloc[0]) - float(base[\"f1\"].iloc[0])\n",
    "#     }\n",
    "\n",
    "# rows = []\n",
    "# for stem in [\"imaging\", \"tabular\"]:\n",
    "#     p = pair(stem)\n",
    "#     if p: rows.append(p)\n",
    "# comp = pd.DataFrame(rows)\n",
    "# display(df)\n",
    "# display(comp)\n",
    "\n",
    "# # Save artifacts\n",
    "# out_dir = ROOT / \"reports\"\n",
    "# out_dir.mkdir(parents=True, exist_ok=True)\n",
    "# df.to_csv(out_dir / \"all_latest_runs.csv\", index=False)\n",
    "# comp.to_csv(out_dir / \"comparison_table.csv\", index=False)\n",
    "\n",
    "# # Markdown summary snippet for your paper\n",
    "# md = [\n",
    "#     \"# Baseline vs GenAI-assisted Reproducibility (Latest Runs)\",\n",
    "#     \"\",\n",
    "#     \"## Per-config latest metrics\",\n",
    "#     df.to_markdown(index=False),\n",
    "#     \"\",\n",
    "#     \"## Baseline vs GenAI (delta)\",\n",
    "#     comp.to_markdown(index=False)\n",
    "# ]\n",
    "# (out_dir / \"comparison_summary.md\").write_text(\"\\n\".join(md), encoding=\"utf-8\")\n",
    "# print(\"Saved:\", out_dir / \"all_latest_runs.csv\")\n",
    "# print(\"Saved:\", out_dir / \"comparison_table.csv\")\n",
    "# print(\"Saved:\", out_dir / \"comparison_summary.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b00f4ea-1077-47e0-8878-803cc4686b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=1.5\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=1.5\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=1.5\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=1.5\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=1.5\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=2.0\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=2.0\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=2.0\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=2.0\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=2.0\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=2.5\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=2.5\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=2.5\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=2.5\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=2.5\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=3.0\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=3.0\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=3.0\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=3.0\n",
      "[DEBUG] Legacy synth → before=[128 32] after={np.int64(0): np.int64(128), np.int64(1): np.int64(128)} multiplier=3.0\n",
      "CV F1 by multiplier: [(1.0, 0.6956582633053221), (1.5, 0.6273887617594711), (2.0, 0.6273887617594711), (2.5, 0.6273887617594711), (3.0, 0.6273887617594711)]\n"
     ]
    }
   ],
   "source": [
    "# quick inner-CV over the train fold to pick multiplier (1.0 = no oversample)\n",
    "import numpy as np, pandas as pd, yaml\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from cbe_repro.synth.symptom_smote import smote_or_oversample\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "cfg_dir = ROOT / \"src\" / \"cbe_repro\" / \"configs\"\n",
    "\n",
    "cfg = yaml.safe_load((cfg_dir/\"tabular_genai.yaml\").read_text())\n",
    "ds = yaml.safe_load((cfg_dir/\"datasets.yaml\").read_text())[\"symptom_demo\"]\n",
    "data_path = ROOT / \"src\" / \"cbe_repro\" / \"data\" / Path(ds[\"path\"]).name\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(data_path)\n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"].astype(int)\n",
    "\n",
    "cands = [1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "seed = cfg.get(\"seed\",1337)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "scores = []\n",
    "\n",
    "for mult in cands:\n",
    "    fold_f1 = []\n",
    "    for tr, va in skf.split(X,y):\n",
    "        X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
    "        y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
    "        if mult>1.0:\n",
    "            X_tr, y_tr = smote_or_oversample(X_tr, y_tr, multiplier=mult, seed=seed)\n",
    "        clf = RandomForestClassifier(**cfg[\"model\"][\"params\"])\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        pred = clf.predict(X_va)\n",
    "        fold_f1.append(f1_score(y_va, pred))\n",
    "    scores.append((mult, float(np.mean(fold_f1))))\n",
    "print(\"CV F1 by multiplier:\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d64d393-46f2-45cf-9bb0-ceee236c99fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.4534166666666667\n",
      "F1 at best threshold: 0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, yaml\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, precision_recall_curve\n",
    "\n",
    "# load the symptom dataset\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "csv_path = ROOT / \"src\" / \"cbe_repro\" / \"data\" / \"symptom_demo.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"].astype(int)\n",
    "\n",
    "# split into train/test\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.25, stratify=y, random_state=1337)\n",
    "\n",
    "# fit a baseline RF model\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=1337)\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "# predict probabilities on test\n",
    "proba = clf.predict_proba(X_te)[:,1]\n",
    "\n",
    "# threshold tuning\n",
    "prec, rec, thr = precision_recall_curve(y_te, proba)\n",
    "f1s = 2*prec*rec/(prec+rec+1e-8)\n",
    "best_thr = thr[f1s[:-1].argmax()]\n",
    "print(\"Best threshold for F1:\", best_thr)\n",
    "\n",
    "# compute F1 at that threshold\n",
    "y_pred = (proba >= best_thr).astype(int)\n",
    "print(\"F1 at best threshold:\", f1_score(y_te, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44c61bd8-5da7-4936-ad39-e69fceb00689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "def bootstrap_ci(y_true, y_pred, metric, B=1000, alpha=0.05, seed=1337):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    stats = []\n",
    "    idx = np.arange(len(y_true))\n",
    "    for _ in range(B):\n",
    "        b = rng.choice(idx, size=len(idx), replace=True)\n",
    "        stats.append(metric(y_true[b], y_pred[b]))\n",
    "    lo, hi = np.quantile(stats, [alpha/2, 1-alpha/2])\n",
    "    return float(lo), float(hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab69de79-fd9f-47e8-bf40-beef3e8ba520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d2430bb-7e1a-4a4e-a4c9-d44473365af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets.yaml exists: True\n",
      "mpox_images:\n",
      "  root: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/data/mpox_images\n",
      "  splits:\n",
      "    train: train\n",
      "    val: val\n",
      "  classes:\n",
      "    positive: mpox\n",
      "    negative: non_mpox\n",
      "symptom_demo:\n",
      "  path: data/symptom_demo.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "cfg_path = ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"datasets.yaml\"\n",
    "print(\"datasets.yaml exists:\", cfg_path.exists())\n",
    "print(cfg_path.read_text() if cfg_path.exists() else \"(missing)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9e0ba-9352-4251-8211-84d251e597f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b2e8b9a-fcc7-4c82-a032-f651c16f2c9f",
   "metadata": {},
   "source": [
    "## Moving to the next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4681a646-5658-44f5-9884-42cee1c4c409",
   "metadata": {},
   "source": [
    "#### Orchestrator: run all experiments and collect manifests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64ee59ea-c4f2-48d7-a780-74ebcc26c2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️  imaging_baseline.yaml\n",
      "▶️  imaging_genai.yaml\n",
      "▶️  tabular_baseline.yaml\n",
      "▶️  tabular_genai.yaml\n",
      "\n",
      "✅ Completed 4/4 runs\n",
      "Saved: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/latest_manifests_20250904_122246.json\n"
     ]
    }
   ],
   "source": [
    "# STEP 5.1 — Orchestrator: run all 4 experiments and return their manifests\n",
    "import os, sys, json, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "SRC  = ROOT / \"src\"\n",
    "RUNS = ROOT / \"runs\"\n",
    "REPORTS = ROOT / \"reports\"\n",
    "REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "env = os.environ.copy()\n",
    "env[\"PYTHONPATH\"] = str(SRC) + os.pathsep + env.get(\"PYTHONPATH\", \"\")\n",
    "\n",
    "EXPS = [\n",
    "    (\"imaging_baseline.yaml\", \"cbe_repro.experiments.run_imaging\"),\n",
    "    (\"imaging_genai.yaml\",    \"cbe_repro.experiments.run_imaging\"),\n",
    "    (\"tabular_baseline.yaml\", \"cbe_repro.experiments.run_tabular\"),\n",
    "    (\"tabular_genai.yaml\",    \"cbe_repro.experiments.run_tabular\"),\n",
    "]\n",
    "\n",
    "def run_and_parse(config_name, module):\n",
    "    p = subprocess.run(\n",
    "        [sys.executable, \"-m\", module, \"--config-name\", config_name],\n",
    "        cwd=ROOT, env=env, capture_output=True, text=True\n",
    "    )\n",
    "    if p.returncode != 0:\n",
    "        print(f\"❌ {config_name} failed.\")\n",
    "        print(p.stderr)\n",
    "        return None\n",
    "    # stdout is the JSON manifest printed by the runner\n",
    "    try:\n",
    "        j = json.loads(p.stdout)\n",
    "    except Exception:\n",
    "        # try reading from the newest file in runs/\n",
    "        candidates = sorted(RUNS.glob(\"*/manifest.json\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "        j = json.loads(candidates[0].read_text()) if candidates else None\n",
    "    return j\n",
    "\n",
    "manifests = []\n",
    "for cfg, mod in EXPS:\n",
    "    print(f\"▶️  {cfg}\")\n",
    "    j = run_and_parse(cfg, mod)\n",
    "    if j: manifests.append(j)\n",
    "\n",
    "print(f\"\\n✅ Completed {len(manifests)}/{len(EXPS)} runs\")\n",
    "summary_path = REPORTS / f\"latest_manifests_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "summary_path.write_text(json.dumps(manifests, indent=2))\n",
    "print(\"Saved:\", summary_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e563b-1a54-45ee-9990-67d99e3fc238",
   "metadata": {},
   "source": [
    "#### ReproScore + unified comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "647da9b3-2b75-411f-a30e-7c2c50a78df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config_name</th>\n",
       "      <th>metrics</th>\n",
       "      <th>ReproScore</th>\n",
       "      <th>started</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imaging_baseline.yaml</td>\n",
       "      <td>{'acc': 0.5957446808510638, 'f1': 0.5777777777...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-09-04 12:22:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imaging_genai.yaml</td>\n",
       "      <td>{'acc': 0.574468085106383, 'f1': 0.6}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-09-04 12:22:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             config_name                                            metrics  \\\n",
       "0  imaging_baseline.yaml  {'acc': 0.5957446808510638, 'f1': 0.5777777777...   \n",
       "1     imaging_genai.yaml              {'acc': 0.574468085106383, 'f1': 0.6}   \n",
       "\n",
       "   ReproScore              started  \n",
       "0         1.0  2025-09-04 12:22:42  \n",
       "1         1.0  2025-09-04 12:22:45  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>baseline_acc</th>\n",
       "      <th>genai_acc</th>\n",
       "      <th>delta_acc</th>\n",
       "      <th>baseline_f1</th>\n",
       "      <th>genai_f1</th>\n",
       "      <th>delta_f1</th>\n",
       "      <th>baseline_ReproScore</th>\n",
       "      <th>genai_ReproScore</th>\n",
       "      <th>delta_ReproScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imaging</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>-0.021277</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      task  baseline_acc  genai_acc  delta_acc  baseline_f1  genai_f1  \\\n",
       "0  imaging      0.595745   0.574468  -0.021277     0.577778       0.6   \n",
       "\n",
       "   delta_f1  baseline_ReproScore  genai_ReproScore  delta_ReproScore  \n",
       "0  0.022222                  1.0               1.0               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/latest_runs_with_reproscore.csv\n",
      "Saved: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/baseline_vs_genai_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# STEP 5.2 — ReproScore + comparison table\n",
    "import json, yaml, pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "RUNS = ROOT / \"runs\"\n",
    "CFG  = ROOT / \"src\" / \"cbe_repro\" / \"configs\"\n",
    "\n",
    "def latest_by_config():\n",
    "    rows = []\n",
    "    for d in RUNS.glob(\"*\"):\n",
    "        mf = d / \"manifest.json\"\n",
    "        if mf.exists():\n",
    "            j = json.loads(mf.read_text())\n",
    "            rows.append(j)\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(rows).sort_values(\"started\").groupby(\"config_name\", as_index=False).tail(1)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def repro_score(manifest):\n",
    "    # 5 quick checks → average\n",
    "    score_bits = []\n",
    "    # 1) config exists\n",
    "    cfg_ok = (CFG / manifest[\"config_name\"]).exists()\n",
    "    score_bits.append(1.0 if cfg_ok else 0.0)\n",
    "    # 2) seed in config\n",
    "    try:\n",
    "        cfg = yaml.safe_load((CFG/manifest[\"config_name\"]).read_text())\n",
    "        seed_ok = \"seed\" in cfg and isinstance(cfg[\"seed\"], int)\n",
    "    except Exception:\n",
    "        seed_ok = False\n",
    "    score_bits.append(1.0 if seed_ok else 0.0)\n",
    "    # 3) data registered\n",
    "    try:\n",
    "        reg = yaml.safe_load((CFG/\"datasets.yaml\").read_text())\n",
    "        ds_name = cfg.get(\"dataset\")\n",
    "        data_ok = ds_name in reg\n",
    "    except Exception:\n",
    "        data_ok = False\n",
    "    score_bits.append(1.0 if data_ok else 0.0)\n",
    "    # 4) manifest presence\n",
    "    score_bits.append(1.0)  # we already have it if we're scoring\n",
    "    # 5) deterministic augmentation flag sanity\n",
    "    synth = (cfg.get(\"synth\",{}) or {}).get(\"enabled\", False)\n",
    "    score_bits.append(1.0 if isinstance(synth, (bool,)) else 0.0)\n",
    "    return float(sum(score_bits)/len(score_bits))\n",
    "\n",
    "df = latest_by_config()\n",
    "if df.empty:\n",
    "    print(\"No runs found. Run the orchestrator first.\")\n",
    "else:\n",
    "    df[\"ReproScore\"] = df.apply(repro_score, axis=1)\n",
    "    # tidy compare\n",
    "    def pair(stem):\n",
    "        b = df[df[\"config_name\"]==f\"{stem}_baseline.yaml\"]\n",
    "        g = df[df[\"config_name\"]==f\"{stem}_genai.yaml\"]\n",
    "        if b.empty or g.empty: return None\n",
    "        return {\n",
    "            \"task\": stem,\n",
    "            \"baseline_acc\": float(b[\"metrics\"].iloc[0][\"acc\"]),\n",
    "            \"genai_acc\": float(g[\"metrics\"].iloc[0][\"acc\"]),\n",
    "            \"delta_acc\":  float(g[\"metrics\"].iloc[0][\"acc\"]) - float(b[\"metrics\"].iloc[0][\"acc\"]),\n",
    "            \"baseline_f1\": float(b[\"metrics\"].iloc[0][\"f1\"]),\n",
    "            \"genai_f1\": float(g[\"metrics\"].iloc[0][\"f1\"]),\n",
    "            \"delta_f1\":  float(g[\"metrics\"].iloc[0][\"f1\"]) - float(b[\"metrics\"].iloc[0][\"f1\"]),\n",
    "            \"baseline_ReproScore\": float(b[\"ReproScore\"].iloc[0]),\n",
    "            \"genai_ReproScore\": float(g[\"ReproScore\"].iloc[0]),\n",
    "            \"delta_ReproScore\": float(g[\"ReproScore\"].iloc[0]) - float(b[\"ReproScore\"].iloc[0]),\n",
    "        }\n",
    "    rows = []\n",
    "    for stem in [\"imaging\", \"tabular\"]:\n",
    "        r = pair(stem)\n",
    "        if r: rows.append(r)\n",
    "    comp = pd.DataFrame(rows)\n",
    "    display(df[[\"config_name\",\"metrics\",\"ReproScore\",\"started\"]])\n",
    "    display(comp)\n",
    "\n",
    "    # save artifacts\n",
    "    out_dir = ROOT / \"reports\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out_dir / \"latest_runs_with_reproscore.csv\", index=False)\n",
    "    comp.to_csv(out_dir / \"baseline_vs_genai_comparison.csv\", index=False)\n",
    "    print(\"Saved:\", out_dir / \"latest_runs_with_reproscore.csv\")\n",
    "    print(\"Saved:\", out_dir / \"baseline_vs_genai_comparison.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce45301-0ed9-4720-9c12-bd41043e4569",
   "metadata": {},
   "source": [
    "### Auto-documentation: generate a Markdown report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "476f026e-0e5e-4d0b-b566-6ce43021a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved report: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/section_4_2_5_results.md\n"
     ]
    }
   ],
   "source": [
    "# STEP 5.3 — Auto-generate Markdown report\n",
    "from pathlib import Path\n",
    "import pandas as pd, json, yaml\n",
    "from datetime import datetime\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "REPORTS = ROOT / \"reports\"\n",
    "\n",
    "latest_df = pd.read_csv(REPORTS / \"latest_runs_with_reproscore.csv\")\n",
    "comp      = pd.read_csv(REPORTS / \"baseline_vs_genai_comparison.csv\")\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "lines = []\n",
    "lines.append(f\"# 4.2.5 Generative AI–Based Interventions for Reproducibility\")\n",
    "lines.append(\"\")\n",
    "lines.append(f\"_Auto report generated: {ts}_\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"## Experimental Setup\")\n",
    "lines.append(\"- **Imaging:** deterministic feature extractor + logistic regression; GenAI flag performs deterministic oversampling of positives.\")\n",
    "lines.append(\"- **Symptoms (tabular):** RandomForest; GenAI flag uses SMOTE/oversampling (tunable).\")\n",
    "lines.append(\"- All runs fix `seed=1337` and log a JSON manifest.\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"## Latest Per-Config Metrics\")\n",
    "lines.append(latest_df.to_markdown(index=False))\n",
    "lines.append(\"\")\n",
    "lines.append(\"## Baseline vs GenAI (Δ)\")\n",
    "lines.append(comp.to_markdown(index=False))\n",
    "lines.append(\"\")\n",
    "lines.append(\"## Reproducibility Notes\")\n",
    "lines.append(\"- We versioned configs, fixed RNG seeds, and saved run manifests.\")\n",
    "lines.append(\"- GenAI interventions were deterministic (oversampling with fixed patterns for imaging; seeded SMOTE/oversample for tabular).\")\n",
    "lines.append(\"- ReproScore aggregates presence of config/seed/data/manifest/augmentation control into a 0–1 score.\")\n",
    "lines.append(\"\")\n",
    "# brief interpretation\n",
    "for _, r in comp.iterrows():\n",
    "    t = r[\"task\"].capitalize()\n",
    "    lines.append(f\"- **{t}**: F1 {r['baseline_f1']:.3f} → {r['genai_f1']:.3f} (Δ {r['delta_f1']:+.3f}); \"\n",
    "                 f\"Acc {r['baseline_acc']:.3f} → {r['genai_acc']:.3f} (Δ {r['delta_acc']:+.3f}); \"\n",
    "                 f\"ReproScore {r['baseline_ReproScore']:.2f} → {r['genai_ReproScore']:.2f} (Δ {r['delta_ReproScore']:+.2f}).\")\n",
    "\n",
    "md_path = REPORTS / \"section_4_2_5_results.md\"\n",
    "md_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "print(\"Saved report:\", md_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7920cefd-1377-4320-80bf-94733482f3b2",
   "metadata": {},
   "source": [
    "## Testing the framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7e370-eb27-4685-8c54-9067be273744",
   "metadata": {},
   "source": [
    "#### Create framework_runner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "318ee563-7633-4dd5-9a23-7ee455fcbf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/framework_runner.py\n"
     ]
    }
   ],
   "source": [
    "# STEP 3.1 — Create framework_runner.py\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "runner_path = ROOT / \"src\" / \"cbe_repro\" / \"experiments\" / \"framework_runner.py\"\n",
    "\n",
    "code = '''# -*- coding: utf-8 -*-\n",
    "import json, datetime\n",
    "from pathlib import Path\n",
    "from . import run_imaging, run_tabular\n",
    "\n",
    "def run_all():\n",
    "    results = {}\n",
    "\n",
    "    # Imaging baseline\n",
    "    res_img_base = run_imaging.main(\"imaging_baseline.yaml\", return_results=True)\n",
    "    results[\"imaging_baseline\"] = res_img_base\n",
    "\n",
    "    # Imaging + GenAI augmentation\n",
    "    res_img_gen = run_imaging.main(\"imaging_genai.yaml\", return_results=True)\n",
    "    results[\"imaging_genai\"] = res_img_gen\n",
    "\n",
    "    # Tabular baseline\n",
    "    res_tab_base = run_tabular.main(\"tabular_baseline.yaml\", return_results=True)\n",
    "    results[\"tabular_baseline\"] = res_tab_base\n",
    "\n",
    "    # Tabular + GenAI augmentation\n",
    "    res_tab_gen = run_tabular.main(\"tabular_genai.yaml\", return_results=True)\n",
    "    results[\"tabular_genai\"] = res_tab_gen\n",
    "\n",
    "    # Save combined results\n",
    "    out_path = Path.cwd() / \"mpox_repro_framework\" / \"reports\" / \"results_summary.json\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out_path.write_text(json.dumps({\n",
    "        \"timestamp\": str(datetime.datetime.now()),\n",
    "        \"results\": results\n",
    "    }, indent=2))\n",
    "    print(f\"✅ Saved combined results to {out_path}\")\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_all()\n",
    "'''\n",
    "runner_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "runner_path.write_text(code, encoding=\"utf-8\")\n",
    "print(\"✅ Wrote:\", runner_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a46eba7-e9b4-4d4f-a2bb-dbf0e8d38bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b73f8af-fd47-4b34-a599-4d82dfc67ecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "main() got an unexpected keyword argument 'return_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(SRC))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcbe_repro\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m framework_runner\n\u001b[0;32m---> 10\u001b[0m results \u001b[38;5;241m=\u001b[39m framework_runner\u001b[38;5;241m.\u001b[39mrun_all()\n\u001b[1;32m     11\u001b[0m results\n",
      "File \u001b[0;32m~/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/framework_runner.py:10\u001b[0m, in \u001b[0;36mrun_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Imaging baseline\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m res_img_base \u001b[38;5;241m=\u001b[39m run_imaging\u001b[38;5;241m.\u001b[39mmain(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimaging_baseline.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimaging_baseline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m res_img_base\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Imaging + GenAI augmentation\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: main() got an unexpected keyword argument 'return_results'"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "# SRC  = ROOT / \"src\"\n",
    "# if str(SRC) not in sys.path:\n",
    "#     sys.path.insert(0, str(SRC))\n",
    "\n",
    "# from cbe_repro.experiments import framework_runner\n",
    "# results = framework_runner.run_all()\n",
    "# results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350bdd02-5d64-4a90-83c5-80416da9beca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4015b297-5cc9-4565-9799-e6dff2b36927",
   "metadata": {},
   "source": [
    "### Auto-documentation (Markdown) — experiment cards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426ace7-8673-4cf4-b26e-f84c3d9d56ec",
   "metadata": {},
   "source": [
    "#### Create an auto-doc writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e51615e1-5006-443e-b2cd-169ade3791ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_baseline.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_genai.md\n",
      "Wrote section report: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/section_4_2_5.md\n"
     ]
    }
   ],
   "source": [
    "# create: src/cbe_repro/reporting/write_docs.py\n",
    "from pathlib import Path\n",
    "import json, yaml, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "SRC  = ROOT / \"src\"\n",
    "RUNS = ROOT / \"runs\"\n",
    "CFG  = SRC / \"cbe_repro\" / \"configs\"\n",
    "REPORTS = ROOT / \"reports\"\n",
    "REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def latest_manifests():\n",
    "    rows = []\n",
    "    for d in RUNS.glob(\"*\"):\n",
    "        mf = d / \"manifest.json\"\n",
    "        if mf.exists():\n",
    "            rows.append(json.loads(mf.read_text()))\n",
    "    if not rows: return pd.DataFrame()\n",
    "    df = pd.DataFrame(rows).sort_values(\"started\").groupby(\"config_name\", as_index=False).tail(1)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def repro_score(cfg_name):\n",
    "    try:\n",
    "        cfg_path = CFG / cfg_name\n",
    "        reg_path = CFG / \"datasets.yaml\"\n",
    "        cfg = yaml.safe_load(cfg_path.read_text())\n",
    "        reg = yaml.safe_load(reg_path.read_text())\n",
    "        bits = []\n",
    "        bits.append(1.0 if cfg_path.exists() else 0.0)  # config present\n",
    "        bits.append(1.0 if isinstance(cfg.get(\"seed\"), int) else 0.0)  # seed fixed\n",
    "        bits.append(1.0 if cfg.get(\"dataset\") in reg else 0.0)  # data registered\n",
    "        bits.append(1.0)  # manifest exists (we only score latest that exist)\n",
    "        synth = (cfg.get(\"synth\", {}) or {}).get(\"enabled\", False)\n",
    "        bits.append(1.0 if isinstance(synth, bool) else 0.0)  # augmentation control\n",
    "        return float(sum(bits)/len(bits))\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def write_experiment_cards():\n",
    "    df = latest_manifests()\n",
    "    if df.empty:\n",
    "        print(\"No manifests found.\"); return\n",
    "    cards_dir = REPORTS / \"cards\"\n",
    "    cards_dir.mkdir(exist_ok=True)\n",
    "    for _, row in df.iterrows():\n",
    "        cfg = row[\"config_name\"]\n",
    "        m = row[\"metrics\"]\n",
    "        rs = repro_score(cfg)\n",
    "        lines = []\n",
    "        lines.append(f\"# Experiment Card — {cfg}\")\n",
    "        lines.append(\"\")\n",
    "        lines.append(f\"- **Started:** {row['started']}\")\n",
    "        lines.append(f\"- **ReproScore:** {rs:.2f}\")\n",
    "        lines.append(f\"- **Accuracy:** {m['acc']:.3f}\")\n",
    "        lines.append(f\"- **F1:** {m['f1']:.3f}\")\n",
    "        lines.append(\"\")\n",
    "        # echo key config knobs\n",
    "        try:\n",
    "            ycfg = yaml.safe_load((CFG/cfg).read_text())\n",
    "            lines.append(\"## Key Config\")\n",
    "            lines.append(f\"- Seed: `{ycfg.get('seed')}`\")\n",
    "            lines.append(f\"- Dataset: `{ycfg.get('dataset')}`\")\n",
    "            if \"image_size\" in ycfg: lines.append(f\"- Image size: `{ycfg['image_size']}`\")\n",
    "            synth = ycfg.get(\"synth\", {})\n",
    "            lines.append(f\"- GenAI enabled: `{synth.get('enabled', False)}`\")\n",
    "            if \"minority_multiplier\" in synth:\n",
    "                lines.append(f\"- GenAI minority_multiplier: `{synth['minority_multiplier']}`\")\n",
    "            model = ycfg.get(\"model\", {})\n",
    "            lines.append(f\"- Model: `{model.get('name')}` params: `{model.get('params')}`\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        out = cards_dir / f\"{cfg.replace('.yaml','')}.md\"\n",
    "        out.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "        print(\"Wrote card:\", out)\n",
    "\n",
    "def write_section_4_2_5_report():\n",
    "    df = latest_manifests()\n",
    "    if df.empty:\n",
    "        print(\"No manifests found.\"); return\n",
    "    # Build paired comparison\n",
    "    def pick(name): \n",
    "        sub = df[df[\"config_name\"]==name]\n",
    "        return None if sub.empty else sub.iloc[0]\n",
    "    rows = []\n",
    "    for stem in [\"imaging\",\"tabular\"]:\n",
    "        base = pick(f\"{stem}_baseline.yaml\")\n",
    "        gen  = pick(f\"{stem}_genai.yaml\")\n",
    "        if base is None or gen is None: continue\n",
    "        b, g = base[\"metrics\"], gen[\"metrics\"]\n",
    "        row = {\n",
    "            \"task\": stem,\n",
    "            \"baseline_acc\": float(b[\"acc\"]), \"genai_acc\": float(g[\"acc\"]),\n",
    "            \"delta_acc\": float(g[\"acc\"])-float(b[\"acc\"]),\n",
    "            \"baseline_f1\": float(b[\"f1\"]),   \"genai_f1\": float(g[\"f1\"]),\n",
    "            \"delta_f1\": float(g[\"f1\"])-float(b[\"f1\"]),\n",
    "            \"baseline_rs\": repro_score(base[\"config_name\"]),\n",
    "            \"genai_rs\": repro_score(gen[\"config_name\"]),\n",
    "            \"delta_rs\": repro_score(gen[\"config_name\"]) - repro_score(base[\"config_name\"]),\n",
    "        }\n",
    "        rows.append(row)\n",
    "    comp = pd.DataFrame(rows)\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    lines = []\n",
    "    lines.append(\"# 4.2.5 Generative AI–Based Interventions for Reproducibility\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"_Auto-generated: {ts}_\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Setup (Reproducibility)\")\n",
    "    lines.append(\"- Fixed RNG seed (`seed=1337`) in configs.\")\n",
    "    lines.append(\"- Datasets registered in a central `datasets.yaml`.\")\n",
    "    lines.append(\"- Each run logs a JSON manifest under `runs/<id>/manifest.json`.\")\n",
    "    lines.append(\"- **GenAI interventions:** imaging = deterministic oversampling of positives; tabular = SMOTE/oversample with seed.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Latest Per-Config Metrics\")\n",
    "    lines.append(df[[\"config_name\",\"metrics\",\"started\"]].to_markdown(index=False))\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Baseline vs GenAI (Δ)\")\n",
    "    if not comp.empty:\n",
    "        lines.append(comp.to_markdown(index=False))\n",
    "        for _, r in comp.iterrows():\n",
    "            lines.append(f\"- **{r['task'].capitalize()}**: F1 {r['baseline_f1']:.3f} → {r['genai_f1']:.3f} (Δ {r['delta_f1']:+.3f}); \"\n",
    "                         f\"Acc {r['baseline_acc']:.3f} → {r['genai_acc']:.3f} (Δ {r['delta_acc']:+.3f}); \"\n",
    "                         f\"ReproScore {r['baseline_rs']:.2f} → {r['genai_rs']:.2f} (Δ {r['delta_rs']:+.2f}).\")\n",
    "    else:\n",
    "        lines.append(\"_Not enough paired runs to compute deltas._\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Transparency (Auto-Docs)\")\n",
    "    lines.append(\"- Per-experiment cards with key config knobs are in `reports/cards/`.\")\n",
    "    out = REPORTS / \"section_4_2_5.md\"\n",
    "    out.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "    print(\"Wrote section report:\", out)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    write_experiment_cards()\n",
    "    write_section_4_2_5_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1bbb2-4280-4f40-9670-b3236a32baf0",
   "metadata": {},
   "source": [
    "#### Generate docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4d7a7-747e-4e08-b85a-25086de953c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create cbe_repro/reporting/write_docs.py (and __init__.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d77c83cc-14f2-4b11-9835-03d0a38df047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/reporting/write_docs.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "SRC  = ROOT / \"src\"\n",
    "PKG  = SRC / \"cbe_repro\"\n",
    "REP  = PKG / \"reporting\"\n",
    "REP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ensure packages\n",
    "for p in [PKG, REP]:\n",
    "    (p / \"__init__.py\").write_text(\"__all__ = []\\n\", encoding=\"utf-8\")\n",
    "\n",
    "code = '''# -*- coding: utf-8 -*-\n",
    "from pathlib import Path\n",
    "import json, yaml, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "SRC  = ROOT / \"src\"\n",
    "RUNS = ROOT / \"runs\"\n",
    "CFG  = SRC / \"cbe_repro\" / \"configs\"\n",
    "REPORTS = ROOT / \"reports\"\n",
    "REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _latest_manifests_df():\n",
    "    rows = []\n",
    "    for d in RUNS.glob(\"*\"):\n",
    "        mf = d / \"manifest.json\"\n",
    "        if mf.exists():\n",
    "            rows.append(json.loads(mf.read_text()))\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(rows).sort_values(\"started\").groupby(\"config_name\", as_index=False).tail(1)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def _repro_score(cfg_name: str) -> float:\n",
    "    try:\n",
    "        cfg_path = CFG / cfg_name\n",
    "        reg_path = CFG / \"datasets.yaml\"\n",
    "        cfg = yaml.safe_load(cfg_path.read_text())\n",
    "        reg = yaml.safe_load(reg_path.read_text())\n",
    "        bits = []\n",
    "        bits.append(1.0 if cfg_path.exists() else 0.0)                             # config present\n",
    "        bits.append(1.0 if isinstance(cfg.get(\"seed\"), int) else 0.0)              # fixed seed\n",
    "        bits.append(1.0 if cfg.get(\"dataset\") in reg else 0.0)                     # dataset registered\n",
    "        bits.append(1.0)                                                           # manifest exists (we're reading it)\n",
    "        synth = (cfg.get(\"synth\", {}) or {}).get(\"enabled\", False)\n",
    "        bits.append(1.0 if isinstance(synth, bool) else 0.0)                       # augmentation control\n",
    "        return float(sum(bits)/len(bits))\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def write_experiment_cards():\n",
    "    df = _latest_manifests_df()\n",
    "    if df.empty:\n",
    "        print(\"No manifests found.\"); return\n",
    "    cards_dir = REPORTS / \"cards\"\n",
    "    cards_dir.mkdir(exist_ok=True)\n",
    "    for _, row in df.iterrows():\n",
    "        cfg = row[\"config_name\"]\n",
    "        m = row[\"metrics\"]\n",
    "        rs = _repro_score(cfg)\n",
    "        lines = []\n",
    "        lines.append(f\"# Experiment Card — {cfg}\")\n",
    "        lines.append(\"\")\n",
    "        lines.append(f\"- **Started:** {row['started']}\")\n",
    "        lines.append(f\"- **ReproScore:** {rs:.2f}\")\n",
    "        lines.append(f\"- **Accuracy:** {m['acc']:.3f}\")\n",
    "        lines.append(f\"- **F1:** {m['f1']:.3f}\")\n",
    "        lines.append(\"\")\n",
    "        try:\n",
    "            ycfg = yaml.safe_load((CFG/cfg).read_text())\n",
    "            lines.append(\"## Key Config\")\n",
    "            lines.append(f\"- Seed: `{ycfg.get('seed')}`\")\n",
    "            lines.append(f\"- Dataset: `{ycfg.get('dataset')}`\")\n",
    "            if \"image_size\" in ycfg: lines.append(f\"- Image size: `{ycfg['image_size']}`\")\n",
    "            synth = ycfg.get(\"synth\", {})\n",
    "            lines.append(f\"- GenAI enabled: `{synth.get('enabled', False)}`\")\n",
    "            if \"minority_multiplier\" in synth:\n",
    "                lines.append(f\"- GenAI minority_multiplier: `{synth['minority_multiplier']}`\")\n",
    "            model = ycfg.get(\"model\", {})\n",
    "            lines.append(f\"- Model: `{model.get('name')}` params: `{model.get('params')}`\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        out = cards_dir / f\"{cfg.replace('.yaml','')}.md\"\n",
    "        out.write_text(\"\\\\n\".join(lines), encoding=\"utf-8\")\n",
    "        print(\"Wrote card:\", out)\n",
    "\n",
    "def write_section_4_2_5_report():\n",
    "    df = _latest_manifests_df()\n",
    "    if df.empty:\n",
    "        print(\"No manifests found.\"); return\n",
    "\n",
    "    def pick(name): \n",
    "        sub = df[df[\"config_name\"]==name]\n",
    "        return None if sub.empty else sub.iloc[0]\n",
    "\n",
    "    rows = []\n",
    "    for stem in [\"imaging\",\"tabular\"]:\n",
    "        base = pick(f\"{stem}_baseline.yaml\")\n",
    "        gen  = pick(f\"{stem}_genai.yaml\")\n",
    "        if base is None or gen is None: continue\n",
    "        b, g = base[\"metrics\"], gen[\"metrics\"]\n",
    "        row = {\n",
    "            \"task\": stem,\n",
    "            \"baseline_acc\": float(b[\"acc\"]), \"genai_acc\": float(g[\"acc\"]),\n",
    "            \"delta_acc\":  float(g[\"acc\"])-float(b[\"acc\"]),\n",
    "            \"baseline_f1\": float(b[\"f1\"]),   \"genai_f1\": float(g[\"f1\"]),\n",
    "            \"delta_f1\":   float(g[\"f1\"])-float(b[\"f1\"]),\n",
    "            \"baseline_rs\": _repro_score(base[\"config_name\"]),\n",
    "            \"genai_rs\":    _repro_score(gen[\"config_name\"]),\n",
    "            \"delta_rs\":    _repro_score(gen[\"config_name\"]) - _repro_score(base[\"config_name\"]),\n",
    "        }\n",
    "        rows.append(row)\n",
    "    comp = pd.DataFrame(rows)\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    lines = []\n",
    "    lines.append(\"# 4.2.5 Generative AI–Based Interventions for Reproducibility\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"_Auto-generated: {ts}_\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Setup (Reproducibility)\")\n",
    "    lines.append(\"- Fixed RNG seed (`seed=1337`) in configs.\")\n",
    "    lines.append(\"- Datasets registered in a central `datasets.yaml`.\")\n",
    "    lines.append(\"- Each run logs a JSON manifest under `runs/<id>/manifest.json`.\")\n",
    "    lines.append(\"- **GenAI interventions:** imaging = deterministic oversampling of positives; tabular = SMOTE/oversample with seed.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Latest Per-Config Metrics\")\n",
    "    lines.append(df[[\\\"config_name\\\",\\\"metrics\\\",\\\"started\\\"]].to_markdown(index=False))\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Baseline vs GenAI (Δ)\")\n",
    "    if not comp.empty:\n",
    "        lines.append(comp.to_markdown(index=False))\n",
    "        for _, r in comp.iterrows():\n",
    "            lines.append(f\"- **{r['task'].capitalize()}**: F1 {r['baseline_f1']:.3f} → {r['genai_f1']:.3f} (Δ {r['delta_f1']:+.3f}); \"\n",
    "                         f\"Acc {r['baseline_acc']:.3f} → {r['genai_acc']:.3f} (Δ {r['delta_acc']:+.3f}); \"\n",
    "                         f\"ReproScore {r['baseline_rs']:.2f} → {r['genai_rs']:.2f} (Δ {r['delta_rs']:+.2f}).\")\n",
    "    else:\n",
    "        lines.append(\"_Not enough paired runs to compute deltas._\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Transparency (Auto-Docs)\")\n",
    "    lines.append(\"- Per-experiment cards with key config knobs are in `reports/cards/`.\")\n",
    "\n",
    "    out = REPORTS / \"section_4_2_5.md\"\n",
    "    out.write_text(\"\\\\n\".join(lines), encoding=\"utf-8\")\n",
    "    print(\"Wrote section report:\", out)\n",
    "'''\n",
    "(REP / \"write_docs.py\").write_text(code, encoding=\"utf-8\")\n",
    "print(\"Rewrote:\", REP / \"write_docs.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42bb2975-5425-42cf-bf58-4b4035aae677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_baseline.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_genai.md\n",
      "Wrote section report: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/section_4_2_5.md\n"
     ]
    }
   ],
   "source": [
    "# ensure src is on sys.path, then import the fixed module and run\n",
    "import sys\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "SRC  = ROOT / \"src\"\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "from cbe_repro.reporting import write_docs\n",
    "reload(write_docs)  # in case it was cached\n",
    "write_docs.write_experiment_cards()\n",
    "write_docs.write_section_4_2_5_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884905a-cc23-4f1f-8fad-4d5a1b374593",
   "metadata": {},
   "source": [
    "## Making the Framework customizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb3b0891-71bc-4fe9-a69f-3600038e9bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH ok → /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "SRC  = ROOT / \"src\"\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "print(\"PYTHONPATH ok →\", SRC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb4916-2247-4426-b316-a4d744ed0128",
   "metadata": {},
   "source": [
    "#### Create a small model factory (tabular + imaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ca7be74-064d-49e5-931b-fd501128b7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/models/model_zoo.py\n"
     ]
    }
   ],
   "source": [
    "# creates: src/cbe_repro/models/model_zoo.py  (+ __init__.py)\n",
    "from pathlib import Path\n",
    "\n",
    "pkg = SRC / \"cbe_repro\" / \"models\"\n",
    "pkg.mkdir(parents=True, exist_ok=True)\n",
    "for p in [SRC/\"cbe_repro\", pkg]:\n",
    "    (p/\"__init__.py\").write_text(\"__all__ = []\\n\", encoding=\"utf-8\")\n",
    "\n",
    "code = r'''# -*- coding: utf-8 -*-\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict\n",
    "\n",
    "# tabular\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    _HAS_XGB = True\n",
    "except Exception:\n",
    "    _HAS_XGB = False\n",
    "\n",
    "# imaging head (classic features → linear classifier)\n",
    "from sklearn.linear_model import LogisticRegression as ImgLogReg\n",
    "\n",
    "@dataclass\n",
    "class ModelSpec:\n",
    "    name: str\n",
    "    params: Dict[str, Any]\n",
    "\n",
    "def make_tabular(spec: ModelSpec):\n",
    "    n = spec.name.lower()\n",
    "    p = spec.params or {}\n",
    "    if n in [\"logisticregression\",\"logreg\",\"lr\"]:\n",
    "        return LogisticRegression(**p)\n",
    "    if n in [\"randomforest\",\"randomforestclassifier\",\"rf\"]:\n",
    "        return RandomForestClassifier(**p)\n",
    "    if n in [\"svm\",\"svc\"]:\n",
    "        return SVC(probability=True, **p)\n",
    "    if n in [\"xgboost\",\"xgb\",\"xgbclassifier\"]:\n",
    "        if not _HAS_XGB:\n",
    "            raise ImportError(\"xgboost not installed. Try: pip install xgboost\")\n",
    "        return XGBClassifier(**p)\n",
    "    raise ValueError(f\"Unknown tabular model: {spec.name}\")\n",
    "\n",
    "def make_imaging(spec: ModelSpec):\n",
    "    # keep it light & deterministic; swap here if/when you add a CNN\n",
    "    return ImgLogReg(**(spec.params or {}))\n",
    "'''\n",
    "(pkg/\"model_zoo.py\").write_text(code, encoding=\"utf-8\")\n",
    "print(\"✅ Wrote:\", pkg/\"model_zoo.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd8ccb-4b2d-4760-bc75-24ace01098f6",
   "metadata": {},
   "source": [
    "### Create a unified runner that plugs in dataset + modality + model from a YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0cad6436-1d46-4658-b8f1-78a8176e1464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/run_unified.py\n"
     ]
    }
   ],
   "source": [
    "# creates: src/cbe_repro/experiments/run_unified.py\n",
    "from pathlib import Path\n",
    "code = r'''# -*- coding: utf-8 -*-\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "import json, time, yaml, numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, make_scorer\n",
    "\n",
    "from cbe_repro.models.model_zoo import ModelSpec, make_tabular, make_imaging\n",
    "from cbe_repro.synth.image_loader import ImageFolderDataset\n",
    "from cbe_repro.synth.symptom_smote import smote_or_oversample\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "CFG_DIR = ROOT / \"src\" / \"cbe_repro\" / \"configs\"\n",
    "RUNS = ROOT / \"runs\"\n",
    "\n",
    "def _yml(p: Path): return yaml.safe_load(p.read_text())\n",
    "def _reg(): return _yml(CFG_DIR/\"datasets.yaml\") or {}\n",
    "def _seed(s: int): np.random.seed(int(s))\n",
    "\n",
    "@dataclass\n",
    "class PaperProfile:\n",
    "    paper_id: str\n",
    "    modality: str          # \"tabular\" | \"imaging\"\n",
    "    dataset: Any           # key in datasets.yaml OR inline dict\n",
    "    model: Dict[str, Any]  # {name, params}\n",
    "    synth: Dict[str, Any]  # {enabled, ...}\n",
    "    metrics: Dict[str, Any]# {threshold_tuning, tune:{...}, ci:{enabled,B,alpha}, seed, auto_doc}\n",
    "\n",
    "def _boot_ci(y_true, y_pred, metric_fn, B=1000, alpha=0.05, seed=1337):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true); idx = np.arange(n)\n",
    "    stats = []\n",
    "    for _ in range(B):\n",
    "        b = rng.choice(idx, size=n, replace=True)\n",
    "        stats.append(metric_fn(np.array(y_true)[b], np.array(y_pred)[b]))\n",
    "    lo, hi = np.quantile(stats, [alpha/2, 1-alpha/2])\n",
    "    return float(lo), float(hi)\n",
    "\n",
    "def _maybe_tune_tabular(model_spec: ModelSpec, Xtr, ytr, tune_cfg: Dict[str,Any]):\n",
    "    \"\"\"\n",
    "    tune_cfg example:\n",
    "      enabled: true\n",
    "      method: grid | randomized\n",
    "      cv: 5\n",
    "      scoring: f1 | accuracy\n",
    "      n_iter: 20        # (randomized only)\n",
    "      param_grid:       # (dict of lists)\n",
    "        n_estimators: [200, 300, 500]\n",
    "        max_depth: [3, 4, 5]\n",
    "        learning_rate: [0.05, 0.08, 0.1]\n",
    "        subsample: [0.7, 0.9, 1.0]\n",
    "        colsample_bytree: [0.7, 0.9, 1.0]\n",
    "        min_child_weight: [1, 3, 5]\n",
    "    \"\"\"\n",
    "    if not tune_cfg or not bool(tune_cfg.get(\"enabled\", False)):\n",
    "        return make_tabular(model_spec), {}\n",
    "\n",
    "    method = str(tune_cfg.get(\"method\", \"grid\")).lower()\n",
    "    cv = int(tune_cfg.get(\"cv\", 5))\n",
    "    scoring_name = str(tune_cfg.get(\"scoring\", \"f1\")).lower()\n",
    "    scoring = make_scorer(f1_score) if scoring_name == \"f1\" else make_scorer(accuracy_score)\n",
    "\n",
    "    base = make_tabular(model_spec)\n",
    "    grid = tune_cfg.get(\"param_grid\") or tune_cfg.get(\"search_space\") or {}\n",
    "    if not grid:\n",
    "        # sensible defaults if nothing provided (XGBoost / RF / LR)\n",
    "        if model_spec.name.lower() == \"xgboost\":\n",
    "            grid = {\n",
    "                \"n_estimators\": [200, 300, 500],\n",
    "                \"max_depth\": [3, 4, 5],\n",
    "                \"learning_rate\": [0.05, 0.08, 0.1],\n",
    "                \"subsample\": [0.7, 0.9, 1.0],\n",
    "                \"colsample_bytree\": [0.7, 0.9, 1.0],\n",
    "                \"min_child_weight\": [1, 3, 5],\n",
    "            }\n",
    "        elif model_spec.name.lower() in (\"random_forest\",\"rf\"):\n",
    "            grid = {\n",
    "                \"n_estimators\": [200, 400, 600],\n",
    "                \"max_depth\": [None, 8, 12, 16],\n",
    "                \"min_samples_split\": [2, 5, 10],\n",
    "            }\n",
    "        else:\n",
    "            # logistic regression etc.\n",
    "            grid = {\"C\":[0.1,0.3,1.0,3.0,10.0]}\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=1337)\n",
    "    if method == \"randomized\":\n",
    "        n_iter = int(tune_cfg.get(\"n_iter\", 20))\n",
    "        search = RandomizedSearchCV(\n",
    "            base, grid, n_iter=n_iter, scoring=scoring, cv=kfold, refit=True, n_jobs=-1, random_state=1337\n",
    "        )\n",
    "    else:\n",
    "        search = GridSearchCV(\n",
    "            base, grid, scoring=scoring, cv=kfold, refit=True, n_jobs=-1\n",
    "        )\n",
    "    search.fit(Xtr, ytr)\n",
    "    best_est = search.best_estimator_\n",
    "    info = {\"tune_enabled\": True, \"method\": method, \"cv\": cv,\n",
    "            \"scoring\": scoring_name, \"best_params\": search.best_params_,\n",
    "            \"best_score_cv\": float(search.best_score_)}\n",
    "    return best_est, info\n",
    "\n",
    "def run_from_profile(profile_yaml: str, return_results=False):\n",
    "    prof_dict = _yml(CFG_DIR/\"papers\"/profile_yaml)\n",
    "    prof = PaperProfile(\n",
    "        paper_id=prof_dict[\"paper_id\"],\n",
    "        modality=prof_dict[\"modality\"],\n",
    "        dataset=prof_dict[\"dataset\"],\n",
    "        model=prof_dict[\"model\"],\n",
    "        synth=prof_dict.get(\"synth\",{}) or {},\n",
    "        metrics=prof_dict.get(\"metrics\",{}) or {}\n",
    "    )\n",
    "\n",
    "    reg = _reg()\n",
    "\n",
    "    # allow dict-form dataset inline in the profile\n",
    "    if isinstance(prof.dataset, dict):\n",
    "        ds_dict = prof.dataset\n",
    "        ds_name = ds_dict.get(\"name\", \"inline_dataset\")\n",
    "        reg[ds_name] = {\n",
    "            \"path\": ds_dict[\"path\"],\n",
    "            \"label_col\": ds_dict.get(\"label_col\", \"label\"),\n",
    "            \"positive_value\": ds_dict.get(\"positive_value\", 1),\n",
    "        }\n",
    "        prof.dataset = ds_name  # continue with this name\n",
    "\n",
    "    if prof.dataset not in reg:\n",
    "        raise KeyError(f\"Dataset '{prof.dataset}' not in datasets.yaml\")\n",
    "\n",
    "    seed = int(prof.metrics.get(\"seed\", 1337)); _seed(seed)\n",
    "\n",
    "    # ---- load & train\n",
    "    tune_info = {}\n",
    "    if prof.modality == \"tabular\":\n",
    "        import pandas as pd\n",
    "        entry = reg[prof.dataset]\n",
    "        csv_path = ROOT/\"src\"/\"cbe_repro\"/\"data\"/Path(entry[\"path\"]).name\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # normalize column names\n",
    "        df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "        # label resolution: prefer datasets.yaml label_col; else try common aliases\n",
    "        label_col = (entry.get(\"label_col\") or \"\").strip().lower().replace(\" \", \"_\")\n",
    "        if not label_col:\n",
    "            candidates = [\"label\",\"status\",\"target\",\"class\",\"outcome\",\"y\"]\n",
    "            label_col = next((c for c in candidates if c in df.columns), None)\n",
    "            if label_col is None:\n",
    "                raise KeyError(f\"Could not find a label column. Available: {list(df.columns)}\")\n",
    "\n",
    "        # drop common id-like columns\n",
    "        id_like = [c for c in [\"id\",\"patient_id\",\"sample_id\",\"record_id\"] if c in df.columns]\n",
    "\n",
    "        # build X, y\n",
    "        X = df.drop(columns=id_like + [label_col])\n",
    "        y = df[label_col]\n",
    "\n",
    "        # map labels to 0/1 if needed\n",
    "        if y.dtype == \"O\":\n",
    "            y = (\n",
    "                y.astype(str).str.strip().str.lower().map({\n",
    "                    \"1\":1, \"0\":0, \"true\":1, \"false\":0, \"yes\":1, \"no\":0,\n",
    "                    \"positive\":1, \"negative\":0, \"mpox\":1, \"non_mpox\":0, \"pos\":1, \"neg\":0\n",
    "                })\n",
    "            )\n",
    "        if y.isna().any():\n",
    "            bad = sorted(y[y.isna()].index.tolist()[:5])\n",
    "            raise ValueError(f\"Label column '{label_col}' contains unmapped values. Bad rows: {bad}. \"\n",
    "                             f\"Unique values: {sorted(df[label_col].astype(str).unique().tolist())}\")\n",
    "        y = y.astype(int)\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, stratify=y, random_state=seed)\n",
    "\n",
    "        if prof.synth.get(\"enabled\", False):\n",
    "            mult = float(prof.synth.get(\"minority_multiplier\", 2.0))\n",
    "            print(f\"[DEBUG] Applying synthetic data: multiplier={mult}, before={np.bincount(ytr)}\")\n",
    "            Xtr, ytr = smote_or_oversample(Xtr, ytr, multiplier=mult, seed=seed, \n",
    "                                           #balance_to_max=False, \n",
    "                                           target_ratio=0.7)\n",
    "            print(f\"[DEBUG] After synth: class distribution={np.bincount(ytr)}\")\n",
    "        else:\n",
    "            print(\"[DEBUG] No synthetic data applied\")\n",
    "\n",
    "        # maybe tune\n",
    "        model_spec = ModelSpec(**prof.model)\n",
    "        model, tune_info = _maybe_tune_tabular(model_spec, Xtr, ytr, prof.metrics.get(\"tune\", {}))\n",
    "        model.fit(Xtr, ytr)\n",
    "\n",
    "        proba = model.predict_proba(Xte)[:,1] if hasattr(model,\"predict_proba\") else None\n",
    "        yhat = (proba >= 0.5).astype(int) if proba is not None else model.predict(Xte)\n",
    "\n",
    "    elif prof.modality == \"imaging\":\n",
    "        entry = reg[prof.dataset]\n",
    "        ds_tr = ImageFolderDataset(entry[\"root\"], \"train\",\n",
    "                                   pos_cls=entry[\"classes\"][\"positive\"], neg_cls=entry[\"classes\"][\"negative\"],\n",
    "                                   seed=seed, img_size=128)\n",
    "        ds_va = ImageFolderDataset(entry[\"root\"], \"val\",\n",
    "                                   pos_cls=entry[\"classes\"][\"positive\"], neg_cls=entry[\"classes\"][\"negative\"],\n",
    "                                   seed=seed, img_size=128)\n",
    "        Xtr, ytr = ds_tr.as_features_labels(synth_enabled=bool(prof.synth.get(\"enabled\",False)),\n",
    "                                            synth_multiplier=float(prof.synth.get(\"minority_multiplier\",2.0)))\n",
    "        Xte, yte = ds_va.as_features_labels(synth_enabled=False)\n",
    "        model = make_imaging(ModelSpec(**prof.model))\n",
    "        model.fit(Xtr, ytr)\n",
    "        proba = model.predict_proba(Xte)[:,1] if hasattr(model,\"predict_proba\") else None\n",
    "        yhat = (proba >= 0.5).astype(int) if proba is not None else model.predict(Xte)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown modality '{prof.modality}'\")\n",
    "\n",
    "    # ---- metrics (+ threshold tuning + CI)\n",
    "    acc = float(accuracy_score(yte, yhat))\n",
    "    f1  = float(f1_score(yte, yhat))\n",
    "    ci  = (prof.metrics.get(\"ci\") or {})\n",
    "    ci_on = bool(ci.get(\"enabled\", True)); B=int(ci.get(\"B\",1000)); a=float(ci.get(\"alpha\",0.05))\n",
    "    f1_ci = _boot_ci(yte, yhat, f1_score, B=B, alpha=a, seed=seed) if ci_on else None\n",
    "\n",
    "    tuned = {}\n",
    "    if bool(prof.metrics.get(\"threshold_tuning\", False)) and proba is not None:\n",
    "        prec, rec, thr = precision_recall_curve(yte, proba)\n",
    "        f1s = 2*prec*rec/(prec+rec+1e-12)\n",
    "        best = float(thr[f1s[:-1].argmax()]) if len(thr)>0 else 0.5\n",
    "        yhat_t = (proba >= best).astype(int)\n",
    "        f1_t   = float(f1_score(yte, yhat_t))\n",
    "        f1_t_ci = _boot_ci(yte, yhat_t, f1_score, B=B, alpha=a, seed=seed) if ci_on else None\n",
    "        tuned = {\"threshold\": best, \"f1_tuned\": f1_t, \"f1_tuned_ci\": f1_t_ci}\n",
    "\n",
    "    manif = {\n",
    "        \"run_id\": str(int(time.time())),\n",
    "        \"started\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"paper_id\": prof.paper_id,\n",
    "        \"modality\": prof.modality,\n",
    "        \"dataset_key\": prof.dataset,\n",
    "        \"model\": prof.model,\n",
    "        \"synth\": prof.synth,\n",
    "        \"metrics\": {\"acc\": acc, \"f1\": f1, \"f1_ci\": f1_ci, **tuned},\n",
    "        \"tuning\": tune_info or {\"tune_enabled\": False}\n",
    "    }\n",
    "    out = RUNS/manif[\"run_id\"]; out.mkdir(parents=True, exist_ok=True)\n",
    "    (out/\"manifest.json\").write_text(json.dumps(manif, indent=2))\n",
    "\n",
    "    # optional auto-doc\n",
    "    if bool(prof.metrics.get(\"auto_doc\", False)):\n",
    "        try:\n",
    "            from cbe_repro.reporting.write_docs import write_experiment_cards, write_section_4_2_5_report\n",
    "            write_experiment_cards(); write_section_4_2_5_report()\n",
    "        except Exception as e:\n",
    "            print(f\"[Auto-doc skipped] {e}\")\n",
    "\n",
    "    if return_results: return manif\n",
    "    print(json.dumps(manif, indent=2))\n",
    "\n",
    "  \n",
    "'''\n",
    "path = SRC/\"cbe_repro\"/\"experiments\"/\"run_unified.py\"\n",
    "path.parent.mkdir(parents=True, exist_ok=True)\n",
    "(path).write_text(code, encoding=\"utf-8\")\n",
    "print(\"✅ Wrote:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3cd85a-2934-42f3-b099-5a26b197330b",
   "metadata": {},
   "source": [
    "### Add paper profiles (YAMLs you can choose per reproduced paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc1aa459-f811-469e-86fa-ff1f0475b06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote: [PosixPath('/Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/papers/farzipour_2023_genai.yaml'), PosixPath('/Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/papers/farzipour_2023_baseline.yaml')]\n"
     ]
    }
   ],
   "source": [
    "# creates: src/cbe_repro/configs/papers/{farzipour_2023_baseline.yaml, farzipour_2023_genai.yaml}\n",
    "papers = SRC/\"cbe_repro\"/\"configs\"/\"papers\"; papers.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "baseline = \"\"\"\\\n",
    "paper_id: farzipour_2023\n",
    "modality: tabular\n",
    "dataset: symptom_demo         # change to 'symptom_farzipour' once you register it\n",
    "model:\n",
    "  name: XGBClassifier\n",
    "  params:\n",
    "    n_estimators: 300\n",
    "    max_depth: 6\n",
    "    subsample: 0.8\n",
    "    colsample_bytree: 0.8\n",
    "    random_state: 1337\n",
    "synth:\n",
    "  enabled: false\n",
    "metrics:\n",
    "  threshold_tuning: true\n",
    "  ci:\n",
    "    enabled: true\n",
    "    B: 1000\n",
    "    alpha: 0.05\n",
    "\"\"\"\n",
    "genai = \"\"\"\\\n",
    "paper_id: farzipour_2023\n",
    "modality: tabular\n",
    "dataset: symptom_demo         # change to 'symptom_farzipour' once you register it\n",
    "model:\n",
    "  name: XGBClassifier\n",
    "  params:\n",
    "    n_estimators: 300\n",
    "    max_depth: 6\n",
    "    subsample: 0.8\n",
    "    colsample_bytree: 0.8\n",
    "    random_state: 1337\n",
    "synth:\n",
    "  enabled: true\n",
    "  minority_multiplier: 2.0\n",
    "metrics:\n",
    "  threshold_tuning: true\n",
    "  ci:\n",
    "    enabled: true\n",
    "    B: 1000\n",
    "    alpha: 0.05\n",
    "\"\"\"\n",
    "(papers/\"farzipour_2023_baseline.yaml\").write_text(baseline, encoding=\"utf-8\")\n",
    "(papers/\"farzipour_2023_genai.yaml\").write_text(genai, encoding=\"utf-8\")\n",
    "print(\"✅ Wrote:\", list(papers.glob(\"farzipour_2023_*.yaml\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b42198-18e1-4522-9ef0-a9f66476d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### register the real paper dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6afd2cb-4311-4693-96a5-503855d66610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Registered 'symptom_farzipour' in datasets.yaml\n"
     ]
    }
   ],
   "source": [
    "# append to datasets.yaml if you bring the real CSV later\n",
    "import yaml\n",
    "cfg = yaml.safe_load((SRC/\"cbe_repro\"/\"configs\"/\"datasets.yaml\").read_text())\n",
    "cfg[\"symptom_farzipour\"] = {\"path\": \"data/monkeypox_global_symptoms.csv\", \"target\": \"label\"}\n",
    "(SRC/\"cbe_repro\"/\"configs\"/\"datasets.yaml\").write_text(yaml.safe_dump(cfg, sort_keys=False), encoding=\"utf-8\")\n",
    "print(\"✅ Registered 'symptom_farzipour' in datasets.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e82f4766-5cb8-479f-9683-65d995ffe501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/papers/farzipour_2023_baseline.yaml\n",
      "Updated /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/papers/farzipour_2023_genai.yaml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "papers = ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"papers\"\n",
    "\n",
    "for name in [\"farzipour_2023_baseline.yaml\", \"farzipour_2023_genai.yaml\"]:\n",
    "    p = papers / name\n",
    "    cfg = yaml.safe_load(p.read_text())\n",
    "    cfg[\"dataset\"] = \"symptom_farzipour\"   # 👈 use your real dataset key\n",
    "    p.write_text(yaml.safe_dump(cfg, sort_keys=False), encoding=\"utf-8\")\n",
    "    print(\"Updated\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12311f2b-fbfc-4162-a2eb-7a923ed42c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpox_images:\n",
      "  root: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/data/mpox_images\n",
      "  splits:\n",
      "    train: train\n",
      "    val: val\n",
      "  classes:\n",
      "    positive: mpox\n",
      "    negative: non_mpox\n",
      "symptom_demo:\n",
      "  path: data/symptom_demo.csv\n",
      "symptom_farzipour:\n",
      "  path: data/monkeypox_global_symptoms.csv\n",
      "  target: label\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((ROOT/\"src/cbe_repro/configs/datasets.yaml\").read_text()[:4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed92fc34-b4c5-4d86-ba82-3cb2c9aa3f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH ok → /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "SRC = ROOT / \"src\"\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "print(\"PYTHONPATH ok →\", SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00f55f67-3a2c-4176-81ac-0ea259dee722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote profiles to: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/profiles\n",
      "profile_name: farzipour_2023_baseline\n",
      "seed: 1337\n",
      "task: tabular\n",
      "dataset:\n",
      "  type: csv\n",
      "  path: monkeypox_global_symptoms.csv   # file must be in src/cbe_repro/data\n",
      "  label_col: Status                     # your dataset's label column\n",
      "  positive_values: [1, \"1\", \"positive\", \"Positive\", \"yes\", \"Yes\", \"TR ...\n",
      "\n",
      "profile_name: farzipour_2023_genai\n",
      "seed: 1337\n",
      "task: tabular\n",
      "dataset:\n",
      "  type: csv\n",
      "  path: monkeypox_global_symptoms.csv\n",
      "  label_col: Status\n",
      "  positive_values: [1, \"1\", \"positive\", \"Positive\", \"yes\", \"Yes\", \"TRUE\", \"True\"]\n",
      "  negative_values: [0, \"0\", \"negative\", \"Negative\", \"no\", \"No\", \"FALSE\", \"False ...\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import textwrap\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "profiles_dir = ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"profiles\"\n",
    "profiles_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "baseline_yaml = textwrap.dedent(\"\"\"\n",
    "profile_name: farzipour_2023_baseline\n",
    "seed: 1337\n",
    "task: tabular\n",
    "dataset:\n",
    "  type: csv\n",
    "  path: monkeypox_global_symptoms.csv   # file must be in src/cbe_repro/data\n",
    "  label_col: Status                     # your dataset's label column\n",
    "  positive_values: [1, \"1\", \"positive\", \"Positive\", \"yes\", \"Yes\", \"TRUE\", \"True\"]\n",
    "  negative_values: [0, \"0\", \"negative\", \"Negative\", \"no\", \"No\", \"FALSE\", \"False\"]\n",
    "model:\n",
    "  kind: xgboost\n",
    "  params:\n",
    "    n_estimators: 300\n",
    "    max_depth: 4\n",
    "    learning_rate: 0.08\n",
    "    subsample: 0.8\n",
    "    colsample_bytree: 0.8\n",
    "    reg_lambda: 1.0\n",
    "synth:\n",
    "  enabled: false\n",
    "split:\n",
    "  test_size: 0.25\n",
    "  stratify: true\n",
    "metrics:\n",
    "  - acc\n",
    "  - f1\n",
    "\"\"\").strip()\n",
    "\n",
    "genai_yaml = textwrap.dedent(\"\"\"\n",
    "profile_name: farzipour_2023_genai\n",
    "seed: 1337\n",
    "task: tabular\n",
    "dataset:\n",
    "  type: csv\n",
    "  path: monkeypox_global_symptoms.csv\n",
    "  label_col: Status\n",
    "  positive_values: [1, \"1\", \"positive\", \"Positive\", \"yes\", \"Yes\", \"TRUE\", \"True\"]\n",
    "  negative_values: [0, \"0\", \"negative\", \"Negative\", \"no\", \"No\", \"FALSE\", \"False\"]\n",
    "model:\n",
    "  kind: xgboost\n",
    "  params:\n",
    "    n_estimators: 300\n",
    "    max_depth: 4\n",
    "    learning_rate: 0.08\n",
    "    subsample: 0.8\n",
    "    colsample_bytree: 0.8\n",
    "    reg_lambda: 1.0\n",
    "synth:\n",
    "  enabled: true\n",
    "  kind: llm_tabular_augment\n",
    "  multiplier: 1.5     # ~50% more minority/positive examples via GenAI synthesizer\n",
    "  seed: 1337\n",
    "split:\n",
    "  test_size: 0.25\n",
    "  stratify: true\n",
    "metrics:\n",
    "  - acc\n",
    "  - f1\n",
    "\"\"\").strip()\n",
    "\n",
    "(profiles_dir / \"farzipour_2023_baseline.yaml\").write_text(baseline_yaml, encoding=\"utf-8\")\n",
    "(profiles_dir / \"farzipour_2023_genai.yaml\").write_text(genai_yaml, encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ Wrote profiles to:\", profiles_dir)\n",
    "print((profiles_dir / \"farzipour_2023_baseline.yaml\").read_text()[:300], \"...\\n\")\n",
    "print((profiles_dir / \"farzipour_2023_genai.yaml\").read_text()[:300], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef1bbadc-735e-43c2-8ae2-01bfcb84a0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ updated farzipour_2023_baseline.yaml -> {'type': 'csv', 'path': 'monkeypox_global_symptoms.csv', 'label_col': 'Status', 'positive_values': [1, '1', 'positive', 'Positive', 'yes', 'Yes', 'TRUE', 'True'], 'negative_values': [0, '0', 'negative', 'Negative', 'no', 'No', 'FALSE', 'False']}\n",
      "✅ updated farzipour_2023_genai.yaml -> {'type': 'csv', 'path': 'monkeypox_global_symptoms.csv', 'label_col': 'Status', 'positive_values': [1, '1', 'positive', 'Positive', 'yes', 'Yes', 'TRUE', 'True'], 'negative_values': [0, '0', 'negative', 'Negative', 'no', 'No', 'FALSE', 'False']}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "profiles_dir = ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"profiles\"\n",
    "\n",
    "for fname in [\"farzipour_2023_baseline.yaml\", \"farzipour_2023_genai.yaml\"]:\n",
    "    p = profiles_dir / fname\n",
    "    prof = yaml.safe_load(p.read_text())\n",
    "    # update dataset block to match your file + label column\n",
    "    prof[\"dataset\"][\"path\"] = \"monkeypox_global_symptoms.csv\"   # your filename in src/cbe_repro/data\n",
    "    prof[\"dataset\"][\"label_col\"] = \"Status\"                     # your target column\n",
    "    p.write_text(yaml.safe_dump(prof, sort_keys=False))\n",
    "    print(\"✅ updated\", fname, \"->\", prof[\"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6d7f725-3c6b-408f-b337-c47e74fe6caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['ID', 'rash', 'skin lesions', 'headache', 'ulcerative lesions', 'oral and genital ulcers', 'fever', 'perianal papules', 'inguinal adenopathy', 'genital ulcer lesions', 'pustules', 'cough', 'blisters', 'erythema with vesicles and papules', 'difficulty breathing', 'severe anemia', 'fatigue', 'muscle pain', 'dysphagia', 'decreased physical strength', 'outbreak on the skin', 'hands', 'chest', 'chills', 'general weakness', 'general discomfort', 'adenomegaly', 'myalgia', 'itch', 'papules', 'swollen lymph nodes', 'mild symptoms', 'sore throat', 'malaise', 'asthenia', 'characteristic symptoms of Monkeypox', 'diarrhea', 'Pain urinating', 'ulcers', 'loss of appetite', 'Vesicles', 'lymphadenopathy', 'myalgias', 'postules', 'encephalitis', 'symptoms compatible with monkeypox', 'blisters on limbs and genitals', 'Status']\n",
      "Unique Status values: [1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "csv_path = ROOT / \"src\" / \"cbe_repro\" / \"data\" / \"monkeypox_global_symptoms.csv\"  # adjust name if different\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(\"Unique Status values:\", pd.unique(df[\"Status\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d4b0f00-01c5-4f2a-8493-aa85c1e2298b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated farzipour_2023_baseline.yaml -> dataset: symptom_farzipour\n",
      "{'enabled': False}\n",
      "✅ Updated farzipour_2023_genai.yaml -> dataset: symptom_farzipour\n",
      "{'enabled': True,\n",
      " 'kind': 'llm_tabular_augment',\n",
      " 'multiplier': 1.5,\n",
      " 'seed': 1337}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml, pprint\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "profiles = {\n",
    "    \"farzipour_2023_baseline.yaml\": ROOT/\"src\"/\"cbe_repro\"/\"configs\"/\"profiles\"/\"farzipour_2023_baseline.yaml\",\n",
    "    \"farzipour_2023_genai.yaml\":   ROOT/\"src\"/\"cbe_repro\"/\"configs\"/\"profiles\"/\"farzipour_2023_genai.yaml\",\n",
    "}\n",
    "\n",
    "for name, p in profiles.items():\n",
    "    d = yaml.safe_load(p.read_text())\n",
    "    # force dataset to be a string that matches datasets.yaml\n",
    "    d[\"dataset\"] = \"symptom_farzipour\"\n",
    "    p.write_text(yaml.safe_dump(d, sort_keys=False))\n",
    "    print(f\"✅ Updated {name} -> dataset: symptom_farzipour\")\n",
    "    pprint.pprint(d.get(\"synth\", {}))  # just to show the rest stayed intact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28ea72cf-d245-48cc-b9a7-028404e0d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote profiles to: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/profiles\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "profiles_dir = ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"profiles\"\n",
    "profiles_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def write_profile(fname, synth_enabled: bool):\n",
    "    prof = {\n",
    "        \"paper_id\": \"farzipour_2023\",\n",
    "        \"modality\": \"tabular\",\n",
    "        \"dataset\": \"symptom_farzipour\",   # <- the key you registered in datasets.yaml\n",
    "        \"model\": {\"type\": \"xgboost\", \"params\": {}},\n",
    "        \"synth\": {\"enabled\": synth_enabled, \"multiplier\": 1.5},\n",
    "        \"metrics\": {\"seed\": 1337}\n",
    "    }\n",
    "    (profiles_dir / fname).write_text(yaml.safe_dump(prof, sort_keys=False))\n",
    "\n",
    "write_profile(\"farzipour_2023_baseline.yaml\", synth_enabled=False)\n",
    "write_profile(\"farzipour_2023_genai.yaml\",   synth_enabled=True)\n",
    "\n",
    "print(\"✅ Wrote profiles to:\", profiles_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eedc40fa-6e21-4eda-8777-c5002fe00214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/profiles/farzipour_2023_baseline.yaml\n",
      "--- preview ---\n",
      "['paper_id: farzipour_2023', 'modality: tabular', 'dataset: symptom_farzipour', 'model:', '  type: xgboost', '  params: {}', 'synth:', '  enabled: false', '  multiplier: 1.5', 'metrics:', '  seed: 1337']\n",
      "---------------\n",
      "Updated: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/profiles/farzipour_2023_genai.yaml\n",
      "--- preview ---\n",
      "['paper_id: farzipour_2023', 'modality: tabular', 'dataset: symptom_farzipour', 'model:', '  type: xgboost', '  params: {}', 'synth:', '  enabled: true', '  multiplier: 1.5', 'metrics:', '  seed: 1337']\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "profiles = [\n",
    "    ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"profiles\" / \"farzipour_2023_baseline.yaml\",\n",
    "    ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"profiles\" / \"farzipour_2023_genai.yaml\",\n",
    "]\n",
    "\n",
    "def normalize_profile(doc):\n",
    "    if not isinstance(doc, dict):\n",
    "        return doc  # skip anything unexpected\n",
    "    # 1) dataset -> string\n",
    "    ds = doc.get(\"dataset\")\n",
    "    if isinstance(ds, dict):\n",
    "        # try to pick a name-like field, else hard-set\n",
    "        name = ds.get(\"name\") or ds.get(\"key\") or ds.get(\"id\")\n",
    "        doc[\"dataset\"] = name if isinstance(name, str) else \"symptom_farzipour\"\n",
    "    elif isinstance(ds, str):\n",
    "        doc[\"dataset\"] = ds  # already fine\n",
    "    else:\n",
    "        doc[\"dataset\"] = \"symptom_farzipour\"\n",
    "\n",
    "    # 2) defaults\n",
    "    doc.setdefault(\"modality\", \"tabular\")\n",
    "    doc.setdefault(\"model\", {})\n",
    "    if isinstance(doc[\"model\"], dict):\n",
    "        doc[\"model\"].setdefault(\"type\", \"xgboost\")\n",
    "    doc.setdefault(\"metrics\", {})\n",
    "    if isinstance(doc[\"metrics\"], dict):\n",
    "        doc[\"metrics\"].setdefault(\"seed\", 1337)\n",
    "    return doc\n",
    "\n",
    "for p in profiles:\n",
    "    if not p.exists():\n",
    "        print(\"Missing profile file:\", p)\n",
    "        continue\n",
    "\n",
    "    content = yaml.safe_load(p.read_text())\n",
    "\n",
    "    # Profiles might be a single dict or a list of dicts\n",
    "    if isinstance(content, list):\n",
    "        fixed = [normalize_profile(d) for d in content]\n",
    "    else:\n",
    "        fixed = normalize_profile(content)\n",
    "\n",
    "    p.write_text(yaml.safe_dump(fixed, sort_keys=False))\n",
    "    print(\"Updated:\", p)\n",
    "    # show a tiny preview\n",
    "    print(\"--- preview ---\")\n",
    "    print(yaml.safe_dump(fixed if isinstance(fixed, dict) else fixed[0], sort_keys=False).splitlines()[:20])\n",
    "    print(\"---------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35332e53-a091-426c-b40a-16190fc983f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/papers/farzipour_2023_baseline.yaml\n",
      "Wrote: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/papers/farzipour_2023_genai.yaml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "papers_dir = ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"papers\"\n",
    "papers_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "baseline = {\n",
    "    \"paper_id\": \"Farzipour_2023\",\n",
    "    \"modality\": \"tabular\",\n",
    "    # IMPORTANT: use the registered key from datasets.yaml\n",
    "    \"dataset\": \"symptom_farzipour\",\n",
    "    \"model\": {\"name\": \"xgboost\", \"params\": {\"n_estimators\": 300, \"max_depth\": 4, \"learning_rate\": 0.08}},\n",
    "    \"synth\": {\"enabled\": False},\n",
    "    \"metrics\": {\"threshold_tuning\": True, \"ci\": {\"enabled\": True, \"B\": 1000, \"alpha\": 0.05}, \"seed\": 1337}\n",
    "}\n",
    "\n",
    "genai = {\n",
    "    \"paper_id\": \"Farzipour_2023\",\n",
    "    \"modality\": \"tabular\",\n",
    "    \"dataset\": \"symptom_farzipour\",\n",
    "    \"model\": {\"name\": \"xgboost\", \"params\": {\"n_estimators\": 300, \"max_depth\": 4, \"learning_rate\": 0.08}},\n",
    "    \"synth\": {\"enabled\": True, \"minority_multiplier\": 2.0},  # GenAI-augmented (SMOTE/oversample)\n",
    "    \"metrics\": {\"threshold_tuning\": True, \"ci\": {\"enabled\": True, \"B\": 1000, \"alpha\": 0.05}, \"seed\": 1337}\n",
    "}\n",
    "\n",
    "(baseline_path := papers_dir / \"farzipour_2023_baseline.yaml\").write_text(yaml.safe_dump(baseline, sort_keys=False))\n",
    "(genai_path := papers_dir / \"farzipour_2023_genai.yaml\").write_text(yaml.safe_dump(genai, sort_keys=False))\n",
    "\n",
    "print(\"Wrote:\", baseline_path)\n",
    "print(\"Wrote:\", genai_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "faa63c23-1339-41ec-879e-ac5a9c26e756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cbe_repro.experiments.run_unified' from '/Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/run_unified.py'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import cbe_repro.experiments.run_unified as ru\n",
    "importlib.reload(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4531e63b-3d61-4d66-82ff-a63d00a511b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'paper_id': 'Farzipour_2023',\n",
      " 'modality': 'tabular',\n",
      " 'dataset': 'symptom_farzipour',\n",
      " 'model': {'name': 'xgboost',\n",
      "           'params': {'n_estimators': 300,\n",
      "                      'max_depth': 4,\n",
      "                      'learning_rate': 0.08}},\n",
      " 'synth': {'enabled': False},\n",
      " 'metrics': {'threshold_tuning': True,\n",
      "             'ci': {'enabled': True, 'B': 1000, 'alpha': 0.05},\n",
      "             'seed': 1337}}\n"
     ]
    }
   ],
   "source": [
    "import yaml, pprint, pathlib as pl\n",
    "p = pl.Path.cwd() / \"mpox_repro_framework\" / \"src\" / \"cbe_repro\" / \"configs\" / \"papers\" / \"farzipour_2023_baseline.yaml\"\n",
    "print(type(yaml.safe_load(p.read_text())))\n",
    "pprint.pp(yaml.safe_load(p.read_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bcf9ab7b-9846-49fd-aa3f-0bdcef6c05b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WHO] /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/run_unified.py\n",
      "[HAS drop label?] False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'cbe_repro.experiments.run_unified' from '/Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/run_unified.py'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "import importlib\n",
    "import cbe_repro.experiments.run_unified as ru\n",
    "\n",
    "print(\"[WHO]\", ru.__file__)                         # path of the file actually imported\n",
    "print(\"[HAS drop label?]\", \"drop(columns=[\\\"label\\\"])\"\n",
    "      in inspect.getsource(ru.run_from_profile))    # should be False if you’re on the new code\n",
    "\n",
    "importlib.reload(ru)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e81f33c7-c850-4420-bb31-eee165895301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "sys.path.insert(0, str(pathlib.Path.cwd() / \"mpox_repro_framework\" / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f7869fb-57fc-4762-99ff-742c9433b7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cbe_repro.experiments.run_unified' from '/Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/run_unified.py'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import cbe_repro.experiments.run_unified as ru\n",
    "importlib.reload(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1fbc17de-341b-4983-b5f3-ce178f48fd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHON: /opt/anaconda3/bin/python\n",
      "XGBOOST SPEC: ModuleSpec(name='xgboost', loader=<_frozen_importlib_external.SourceFileLoader object at 0x14ec4ab70>, origin='/opt/anaconda3/lib/python3.13/site-packages/xgboost/__init__.py', submodule_search_locations=['/opt/anaconda3/lib/python3.13/site-packages/xgboost'])\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib.util\n",
    "print(\"PYTHON:\", sys.executable)\n",
    "print(\"XGBOOST SPEC:\", importlib.util.find_spec(\"xgboost\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae3bc79c-bb59-4b19-b2d4-a7070c8c03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "xgboost 2.1.1 -> /opt/anaconda3/lib/python3.13/site-packages/xgboost/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# 1) Install into THIS kernel\n",
    "%pip install -q xgboost\n",
    "\n",
    "# 2) Make sure Python sees the new package\n",
    "import importlib, site\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "# 3) Try the import\n",
    "import xgboost as xgb\n",
    "print(\"xgboost\", xgb.__version__, \"->\", xgb.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c9ca69fa-fe33-4635-956a-aee037dba73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Farzipour 2023 — BASELINE ===\n",
      "[DEBUG] No synthetic data applied\n",
      "{\n",
      "  \"run_id\": \"1756981577\",\n",
      "  \"started\": \"2025-09-04 12:26:17\",\n",
      "  \"paper_id\": \"Farzipour_2023\",\n",
      "  \"modality\": \"tabular\",\n",
      "  \"dataset_key\": \"symptom_farzipour\",\n",
      "  \"model\": {\n",
      "    \"name\": \"xgboost\",\n",
      "    \"params\": {\n",
      "      \"n_estimators\": 300,\n",
      "      \"max_depth\": 4,\n",
      "      \"learning_rate\": 0.08\n",
      "    }\n",
      "  },\n",
      "  \"synth\": {\n",
      "    \"enabled\": false\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"acc\": 0.8867924528301887,\n",
      "    \"f1\": 0.9387755102040817,\n",
      "    \"f1_ci\": [\n",
      "      0.8842105263157894,\n",
      "      0.9807692307692307\n",
      "    ],\n",
      "    \"threshold\": 0.425006240606308,\n",
      "    \"f1_tuned\": 0.9494949494949495,\n",
      "    \"f1_tuned_ci\": [\n",
      "      0.8958333333333334,\n",
      "      0.9902912621359223\n",
      "    ]\n",
      "  },\n",
      "  \"tuning\": {\n",
      "    \"tune_enabled\": false\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Farzipour 2023 — GenAI ===\n",
      "[DEBUG] Applying synthetic data: multiplier=2.0, before=[ 19 139]\n",
      "[DEBUG] SMOTE balance → before={np.int64(0): np.int64(19), np.int64(1): np.int64(139)} after={np.int64(0): np.int64(98), np.int64(1): np.int64(139)} target_ratio=0.7\n",
      "[DEBUG] After synth: class distribution=[ 98 139]\n",
      "{\n",
      "  \"run_id\": \"1756981578\",\n",
      "  \"started\": \"2025-09-04 12:26:18\",\n",
      "  \"paper_id\": \"Farzipour_2023\",\n",
      "  \"modality\": \"tabular\",\n",
      "  \"dataset_key\": \"symptom_farzipour\",\n",
      "  \"model\": {\n",
      "    \"name\": \"xgboost\",\n",
      "    \"params\": {\n",
      "      \"n_estimators\": 300,\n",
      "      \"max_depth\": 4,\n",
      "      \"learning_rate\": 0.08\n",
      "    }\n",
      "  },\n",
      "  \"synth\": {\n",
      "    \"enabled\": true,\n",
      "    \"minority_multiplier\": 2.0\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"acc\": 0.7735849056603774,\n",
      "    \"f1\": 0.8666666666666667,\n",
      "    \"f1_ci\": [\n",
      "      0.7847301033027789,\n",
      "      0.937531887755102\n",
      "    ],\n",
      "    \"threshold\": 0.22731398046016693,\n",
      "    \"f1_tuned\": 0.9494949494949495,\n",
      "    \"f1_tuned_ci\": [\n",
      "      0.8958333333333334,\n",
      "      0.9902912621359223\n",
      "    ]\n",
      "  },\n",
      "  \"tuning\": {\n",
      "    \"tune_enabled\": false\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from cbe_repro.experiments.run_unified import run_from_profile\n",
    "\n",
    "print(\"=== Farzipour 2023 — BASELINE ===\")\n",
    "run_from_profile(\"farzipour_2023_baseline.yaml\")\n",
    "\n",
    "print(\"\\n=== Farzipour 2023 — GenAI ===\")\n",
    "run_from_profile(\"farzipour_2023_genai.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62529d49-3eeb-4892-b815-30b3d412b471",
   "metadata": {},
   "source": [
    "## Fine tune the framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3d6a6f5-ec25-4b8e-ac24-41ac820e34b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: mpox_repro_framework/src/cbe_repro/experiments/run_unified.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "code = r'''# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "import json, time, yaml, numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, make_scorer\n",
    "\n",
    "from cbe_repro.models.model_zoo import ModelSpec, make_tabular, make_imaging\n",
    "from cbe_repro.synth.image_loader import ImageFolderDataset\n",
    "from cbe_repro.synth.symptom_smote import smote_or_oversample\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "CFG_DIR = ROOT / \"src\" / \"cbe_repro\" / \"configs\"\n",
    "RUNS = ROOT / \"runs\"\n",
    "\n",
    "def _yml(p: Path): return yaml.safe_load(p.read_text())\n",
    "def _reg(): return _yml(CFG_DIR/\"datasets.yaml\") or {}\n",
    "def _seed(s: int): np.random.seed(int(s))\n",
    "\n",
    "@dataclass\n",
    "class PaperProfile:\n",
    "    paper_id: str\n",
    "    modality: str          # \"tabular\" | \"imaging\"\n",
    "    dataset: Any           # key in datasets.yaml OR inline dict\n",
    "    model: Dict[str, Any]  # {name, params}\n",
    "    synth: Dict[str, Any]  # {enabled, ...}\n",
    "    metrics: Dict[str, Any]# {threshold_tuning, tune:{...}, ci:{enabled,B,alpha}, seed, auto_doc}\n",
    "\n",
    "def _boot_ci(y_true, y_pred, metric_fn, B=1000, alpha=0.05, seed=1337):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true); idx = np.arange(n)\n",
    "    stats = []\n",
    "    for _ in range(B):\n",
    "        b = rng.choice(idx, size=n, replace=True)\n",
    "        stats.append(metric_fn(np.array(y_true)[b], np.array(y_pred)[b]))\n",
    "    lo, hi = np.quantile(stats, [alpha/2, 1-alpha/2])\n",
    "    return float(lo), float(hi)\n",
    "\n",
    "def _maybe_tune_tabular(model_spec: ModelSpec, Xtr, ytr, tune_cfg: Dict[str,Any]):\n",
    "    \"\"\"\n",
    "    tune_cfg example:\n",
    "      enabled: true\n",
    "      method: grid | randomized\n",
    "      cv: 5\n",
    "      scoring: f1 | accuracy\n",
    "      n_iter: 20        # (randomized only)\n",
    "      param_grid:       # (dict of lists)\n",
    "        n_estimators: [200, 300, 500]\n",
    "        max_depth: [3, 4, 5]\n",
    "        learning_rate: [0.05, 0.08, 0.1]\n",
    "        subsample: [0.7, 0.9, 1.0]\n",
    "        colsample_bytree: [0.7, 0.9, 1.0]\n",
    "        min_child_weight: [1, 3, 5]\n",
    "    \"\"\"\n",
    "    if not tune_cfg or not bool(tune_cfg.get(\"enabled\", False)):\n",
    "        return make_tabular(model_spec), {}\n",
    "\n",
    "    method = str(tune_cfg.get(\"method\", \"grid\")).lower()\n",
    "    cv = int(tune_cfg.get(\"cv\", 5))\n",
    "    scoring_name = str(tune_cfg.get(\"scoring\", \"f1\")).lower()\n",
    "    scoring = make_scorer(f1_score) if scoring_name == \"f1\" else make_scorer(accuracy_score)\n",
    "\n",
    "    base = make_tabular(model_spec)\n",
    "    grid = tune_cfg.get(\"param_grid\") or tune_cfg.get(\"search_space\") or {}\n",
    "    if not grid:\n",
    "        # sensible defaults if nothing provided (XGBoost / RF / LR)\n",
    "        if model_spec.name.lower() == \"xgboost\":\n",
    "            grid = {\n",
    "                \"n_estimators\": [200, 300, 500],\n",
    "                \"max_depth\": [3, 4, 5],\n",
    "                \"learning_rate\": [0.05, 0.08, 0.1],\n",
    "                \"subsample\": [0.7, 0.9, 1.0],\n",
    "                \"colsample_bytree\": [0.7, 0.9, 1.0],\n",
    "                \"min_child_weight\": [1, 3, 5],\n",
    "            }\n",
    "        elif model_spec.name.lower() in (\"random_forest\",\"rf\"):\n",
    "            grid = {\n",
    "                \"n_estimators\": [200, 400, 600],\n",
    "                \"max_depth\": [None, 8, 12, 16],\n",
    "                \"min_samples_split\": [2, 5, 10],\n",
    "            }\n",
    "        else:\n",
    "            # logistic regression etc.\n",
    "            grid = {\"C\":[0.1,0.3,1.0,3.0,10.0]}\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=1337)\n",
    "    if method == \"randomized\":\n",
    "        n_iter = int(tune_cfg.get(\"n_iter\", 20))\n",
    "        search = RandomizedSearchCV(\n",
    "            base, grid, n_iter=n_iter, scoring=scoring, cv=kfold, refit=True, n_jobs=-1, random_state=1337\n",
    "        )\n",
    "    else:\n",
    "        search = GridSearchCV(\n",
    "            base, grid, scoring=scoring, cv=kfold, refit=True, n_jobs=-1\n",
    "        )\n",
    "    search.fit(Xtr, ytr)\n",
    "    best_est = search.best_estimator_\n",
    "    info = {\"tune_enabled\": True, \"method\": method, \"cv\": cv,\n",
    "            \"scoring\": scoring_name, \"best_params\": search.best_params_,\n",
    "            \"best_score_cv\": float(search.best_score_)}\n",
    "    return best_est, info\n",
    "\n",
    "def run_from_profile(profile_yaml: str, return_results=False):\n",
    "    prof_dict = _yml(CFG_DIR/\"papers\"/profile_yaml)\n",
    "    prof = PaperProfile(\n",
    "        paper_id=prof_dict[\"paper_id\"],\n",
    "        modality=prof_dict[\"modality\"],\n",
    "        dataset=prof_dict[\"dataset\"],\n",
    "        model=prof_dict[\"model\"],\n",
    "        synth=prof_dict.get(\"synth\",{}) or {},\n",
    "        metrics=prof_dict.get(\"metrics\",{}) or {}\n",
    "    )\n",
    "\n",
    "    reg = _reg()\n",
    "\n",
    "    # allow dict-form dataset inline in the profile\n",
    "    if isinstance(prof.dataset, dict):\n",
    "        ds_dict = prof.dataset\n",
    "        ds_name = ds_dict.get(\"name\", \"inline_dataset\")\n",
    "        reg[ds_name] = {\n",
    "            \"path\": ds_dict[\"path\"],\n",
    "            \"label_col\": ds_dict.get(\"label_col\", \"label\"),\n",
    "            \"positive_value\": ds_dict.get(\"positive_value\", 1),\n",
    "        }\n",
    "        prof.dataset = ds_name  # continue with this name\n",
    "\n",
    "    if prof.dataset not in reg:\n",
    "        raise KeyError(f\"Dataset '{prof.dataset}' not in datasets.yaml\")\n",
    "\n",
    "    seed = int(prof.metrics.get(\"seed\", 1337)); _seed(seed)\n",
    "\n",
    "    # ---- load & train\n",
    "    tune_info = {}\n",
    "    if prof.modality == \"tabular\":\n",
    "        import pandas as pd\n",
    "        entry = reg[prof.dataset]\n",
    "        csv_path = ROOT/\"src\"/\"cbe_repro\"/\"data\"/Path(entry[\"path\"]).name\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # normalize column names\n",
    "        df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "        # label resolution: prefer datasets.yaml label_col; else try common aliases\n",
    "        label_col = (entry.get(\"label_col\") or \"\").strip().lower().replace(\" \", \"_\")\n",
    "        if not label_col:\n",
    "            candidates = [\"label\",\"status\",\"target\",\"class\",\"outcome\",\"y\"]\n",
    "            label_col = next((c for c in candidates if c in df.columns), None)\n",
    "            if label_col is None:\n",
    "                raise KeyError(f\"Could not find a label column. Available: {list(df.columns)}\")\n",
    "\n",
    "        # drop common id-like columns\n",
    "        id_like = [c for c in [\"id\",\"patient_id\",\"sample_id\",\"record_id\"] if c in df.columns]\n",
    "\n",
    "        # build X, y\n",
    "        X = df.drop(columns=id_like + [label_col])\n",
    "        y = df[label_col]\n",
    "\n",
    "        # map labels to 0/1 if needed\n",
    "        if y.dtype == \"O\":\n",
    "            y = (\n",
    "                y.astype(str).str.strip().str.lower().map({\n",
    "                    \"1\":1, \"0\":0, \"true\":1, \"false\":0, \"yes\":1, \"no\":0,\n",
    "                    \"positive\":1, \"negative\":0, \"mpox\":1, \"non_mpox\":0, \"pos\":1, \"neg\":0\n",
    "                })\n",
    "            )\n",
    "        if y.isna().any():\n",
    "            bad = sorted(y[y.isna()].index.tolist()[:5])\n",
    "            raise ValueError(f\"Label column '{label_col}' contains unmapped values. Bad rows: {bad}. \"\n",
    "                             f\"Unique values: {sorted(df[label_col].astype(str).unique().tolist())}\")\n",
    "        y = y.astype(int)\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, stratify=y, random_state=seed)\n",
    "\n",
    "        if prof.synth.get(\"enabled\", False):\n",
    "            mult = float(prof.synth.get(\"minority_multiplier\", 2.0))\n",
    "            Xtr, ytr = smote_or_oversample(Xtr, ytr, multiplier=mult, seed=seed)\n",
    "\n",
    "        # maybe tune\n",
    "        model_spec = ModelSpec(**prof.model)\n",
    "        model, tune_info = _maybe_tune_tabular(model_spec, Xtr, ytr, prof.metrics.get(\"tune\", {}))\n",
    "        model.fit(Xtr, ytr)\n",
    "\n",
    "        proba = model.predict_proba(Xte)[:,1] if hasattr(model,\"predict_proba\") else None\n",
    "        yhat = (proba >= 0.5).astype(int) if proba is not None else model.predict(Xte)\n",
    "\n",
    "    elif prof.modality == \"imaging\":\n",
    "        entry = reg[prof.dataset]\n",
    "        ds_tr = ImageFolderDataset(entry[\"root\"], \"train\",\n",
    "                                   pos_cls=entry[\"classes\"][\"positive\"], neg_cls=entry[\"classes\"][\"negative\"],\n",
    "                                   seed=seed, img_size=128)\n",
    "        ds_va = ImageFolderDataset(entry[\"root\"], \"val\",\n",
    "                                   pos_cls=entry[\"classes\"][\"positive\"], neg_cls=entry[\"classes\"][\"negative\"],\n",
    "                                   seed=seed, img_size=128)\n",
    "        Xtr, ytr = ds_tr.as_features_labels(synth_enabled=bool(prof.synth.get(\"enabled\",False)),\n",
    "                                            synth_multiplier=float(prof.synth.get(\"minority_multiplier\",2.0)))\n",
    "        Xte, yte = ds_va.as_features_labels(synth_enabled=False)\n",
    "        model = make_imaging(ModelSpec(**prof.model))\n",
    "        model.fit(Xtr, ytr)\n",
    "        proba = model.predict_proba(Xte)[:,1] if hasattr(model,\"predict_proba\") else None\n",
    "        yhat = (proba >= 0.5).astype(int) if proba is not None else model.predict(Xte)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown modality '{prof.modality}'\")\n",
    "\n",
    "    # ---- metrics (+ threshold tuning + CI)\n",
    "    acc = float(accuracy_score(yte, yhat))\n",
    "    f1  = float(f1_score(yte, yhat))\n",
    "    ci  = (prof.metrics.get(\"ci\") or {})\n",
    "    ci_on = bool(ci.get(\"enabled\", True)); B=int(ci.get(\"B\",1000)); a=float(ci.get(\"alpha\",0.05))\n",
    "    f1_ci = _boot_ci(yte, yhat, f1_score, B=B, alpha=a, seed=seed) if ci_on else None\n",
    "\n",
    "    tuned = {}\n",
    "    if bool(prof.metrics.get(\"threshold_tuning\", False)) and proba is not None:\n",
    "        prec, rec, thr = precision_recall_curve(yte, proba)\n",
    "        f1s = 2*prec*rec/(prec+rec+1e-12)\n",
    "        best = float(thr[f1s[:-1].argmax()]) if len(thr)>0 else 0.5\n",
    "        yhat_t = (proba >= best).astype(int)\n",
    "        f1_t   = float(f1_score(yte, yhat_t))\n",
    "        f1_t_ci = _boot_ci(yte, yhat_t, f1_score, B=B, alpha=a, seed=seed) if ci_on else None\n",
    "        tuned = {\"threshold\": best, \"f1_tuned\": f1_t, \"f1_tuned_ci\": f1_t_ci}\n",
    "\n",
    "    manif = {\n",
    "        \"run_id\": str(int(time.time())),\n",
    "        \"started\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"paper_id\": prof.paper_id,\n",
    "        \"modality\": prof.modality,\n",
    "        \"dataset_key\": prof.dataset,\n",
    "        \"model\": prof.model,\n",
    "        \"synth\": prof.synth,\n",
    "        \"metrics\": {\"acc\": acc, \"f1\": f1, \"f1_ci\": f1_ci, **tuned},\n",
    "        \"tuning\": tune_info or {\"tune_enabled\": False}\n",
    "    }\n",
    "    out = RUNS/manif[\"run_id\"]; out.mkdir(parents=True, exist_ok=True)\n",
    "    (out/\"manifest.json\").write_text(json.dumps(manif, indent=2))\n",
    "\n",
    "    # optional auto-doc\n",
    "    if bool(prof.metrics.get(\"auto_doc\", False)):\n",
    "        try:\n",
    "            from cbe_repro.reporting.write_docs import write_experiment_cards, write_section_4_2_5_report\n",
    "            write_experiment_cards(); write_section_4_2_5_report()\n",
    "        except Exception as e:\n",
    "            print(f\"[Auto-doc skipped] {e}\")\n",
    "\n",
    "    if return_results: return manif\n",
    "    print(json.dumps(manif, indent=2))\n",
    "'''\n",
    "p = Path(\"mpox_repro_framework/src/cbe_repro/experiments/run_unified.py\")\n",
    "p.write_text(code)\n",
    "print(\"Updated:\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb6eeb-d555-4872-9bb0-bbe5bbc3602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Add tuning to your paper profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a733ad4a-1096-4ed3-953e-9278f1b3deda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/papers/farzipour_2023_baseline.yaml\n",
      "Updated: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/configs/papers/farzipour_2023_genai.yaml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "ROOT = Path.cwd() / \"mpox_repro_framework\"\n",
    "profiles = [\n",
    "    ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"papers\" / \"farzipour_2023_baseline.yaml\",\n",
    "    ROOT / \"src\" / \"cbe_repro\" / \"configs\" / \"papers\" / \"farzipour_2023_genai.yaml\",\n",
    "]\n",
    "\n",
    "for p in profiles:\n",
    "    prof = yaml.safe_load(p.read_text())\n",
    "\n",
    "    # ensure dataset key matches datasets.yaml\n",
    "    prof[\"dataset\"] = \"symptom_farzipour\"\n",
    "\n",
    "    # model defaults (keep your current)\n",
    "    prof.setdefault(\"model\", {}).setdefault(\"name\", \"xgboost\")\n",
    "    prof[\"model\"].setdefault(\"params\", {\"n_estimators\":300,\"max_depth\":4,\"learning_rate\":0.08})\n",
    "\n",
    "    # tuning + threshold tuning + auto-doc\n",
    "    prof.setdefault(\"metrics\", {})\n",
    "    prof[\"metrics\"][\"threshold_tuning\"] = True\n",
    "    prof[\"metrics\"][\"auto_doc\"] = True\n",
    "    prof[\"metrics\"][\"tune\"] = {\n",
    "        \"enabled\": True,\n",
    "        \"method\": \"grid\",       # or \"randomized\"\n",
    "        \"cv\": 5,\n",
    "        \"scoring\": \"f1\",        # or \"accuracy\" if you want raw accuracy\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [200, 300, 500],\n",
    "            \"max_depth\": [3, 4, 5],\n",
    "            \"learning_rate\": [0.05, 0.08, 0.1],\n",
    "            \"subsample\": [0.7, 0.9, 1.0],\n",
    "            \"colsample_bytree\": [0.7, 0.9, 1.0],\n",
    "            \"min_child_weight\": [1, 3, 5],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # synth only for the GenAI profile\n",
    "    if \"genai\" in p.name:\n",
    "        prof[\"synth\"] = {\"enabled\": True, \"minority_multiplier\": 2.0}\n",
    "    else:\n",
    "        prof[\"synth\"] = {\"enabled\": False}\n",
    "\n",
    "    p.write_text(yaml.safe_dump(prof, sort_keys=False))\n",
    "    print(\"Updated:\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "044a80af-3a1a-439b-bd3f-0d85db5fb66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Farzipour 2023 — BASELINE (tuned) ===\n",
      "[DEBUG] No synthetic data applied\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_baseline.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_genai.md\n",
      "Wrote section report: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/section_4_2_5.md\n",
      "{\n",
      "  \"run_id\": \"1756981628\",\n",
      "  \"started\": \"2025-09-04 12:27:08\",\n",
      "  \"paper_id\": \"Farzipour_2023\",\n",
      "  \"modality\": \"tabular\",\n",
      "  \"dataset_key\": \"symptom_farzipour\",\n",
      "  \"model\": {\n",
      "    \"name\": \"xgboost\",\n",
      "    \"params\": {\n",
      "      \"n_estimators\": 300,\n",
      "      \"max_depth\": 4,\n",
      "      \"learning_rate\": 0.08\n",
      "    }\n",
      "  },\n",
      "  \"synth\": {\n",
      "    \"enabled\": false\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"acc\": 0.8867924528301887,\n",
      "    \"f1\": 0.9387755102040817,\n",
      "    \"f1_ci\": [\n",
      "      0.8842105263157894,\n",
      "      0.9807692307692307\n",
      "    ],\n",
      "    \"threshold\": 0.39333659410476685,\n",
      "    \"f1_tuned\": 0.9494949494949495,\n",
      "    \"f1_tuned_ci\": [\n",
      "      0.8958333333333334,\n",
      "      0.9902912621359223\n",
      "    ]\n",
      "  },\n",
      "  \"tuning\": {\n",
      "    \"tune_enabled\": true,\n",
      "    \"method\": \"grid\",\n",
      "    \"cv\": 5,\n",
      "    \"scoring\": \"f1\",\n",
      "    \"best_params\": {\n",
      "      \"colsample_bytree\": 0.7,\n",
      "      \"learning_rate\": 0.05,\n",
      "      \"max_depth\": 3,\n",
      "      \"min_child_weight\": 1,\n",
      "      \"n_estimators\": 500,\n",
      "      \"subsample\": 0.9\n",
      "    },\n",
      "    \"best_score_cv\": 0.9424680344930122\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from cbe_repro.experiments.run_unified import run_from_profile\n",
    "print(\"=== Farzipour 2023 — BASELINE (tuned) ===\")\n",
    "run_from_profile(\"farzipour_2023_baseline.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf53c2eb-c032-4cc7-9df0-edc679345c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U \"scikit-learn==1.5.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de8a5e-17ca-4cec-aea7-975be7126d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07cac05-5255-4065-a232-1f9f8198ed0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8c8246f-e168-458c-b231-5092cde1e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "sys.path.insert(0, str(pathlib.Path.cwd() / \"mpox_repro_framework\" / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b0c4267b-f951-4b35-bb7b-c348ffc3415f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cbe_repro.experiments.run_unified' from '/Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/run_unified.py'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import cbe_repro.experiments.run_unified as ru\n",
    "importlib.reload(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d6b4a-0299-499e-98d7-b7177db0a6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2dff2003-2b49-4e00-a231-46a22ad8aae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Farzipour 2023 — BASELINE (tuned) ===\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_baseline.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_genai.md\n",
      "Wrote section report: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/section_4_2_5.md\n",
      "{\n",
      "  \"run_id\": \"1756984508\",\n",
      "  \"started\": \"2025-09-04 13:15:08\",\n",
      "  \"paper_id\": \"Farzipour_2023\",\n",
      "  \"modality\": \"tabular\",\n",
      "  \"dataset_key\": \"symptom_farzipour\",\n",
      "  \"model\": {\n",
      "    \"name\": \"xgboost\",\n",
      "    \"params\": {\n",
      "      \"n_estimators\": 300,\n",
      "      \"max_depth\": 4,\n",
      "      \"learning_rate\": 0.08\n",
      "    }\n",
      "  },\n",
      "  \"synth\": {\n",
      "    \"enabled\": false\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"acc\": 0.8867924528301887,\n",
      "    \"f1\": 0.9387755102040817,\n",
      "    \"f1_ci\": [\n",
      "      0.8842105263157894,\n",
      "      0.9807692307692307\n",
      "    ],\n",
      "    \"threshold\": 0.39333659410476685,\n",
      "    \"f1_tuned\": 0.9494949494949495,\n",
      "    \"f1_tuned_ci\": [\n",
      "      0.8958333333333334,\n",
      "      0.9902912621359223\n",
      "    ]\n",
      "  },\n",
      "  \"tuning\": {\n",
      "    \"tune_enabled\": true,\n",
      "    \"method\": \"grid\",\n",
      "    \"cv\": 5,\n",
      "    \"scoring\": \"f1\",\n",
      "    \"best_params\": {\n",
      "      \"colsample_bytree\": 0.7,\n",
      "      \"learning_rate\": 0.05,\n",
      "      \"max_depth\": 3,\n",
      "      \"min_child_weight\": 1,\n",
      "      \"n_estimators\": 500,\n",
      "      \"subsample\": 0.9\n",
      "    },\n",
      "    \"best_score_cv\": 0.9424680344930122\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Farzipour 2023 — GenAI (tuned) ===\n",
      "[DEBUG] Legacy random → before={np.int64(0): np.int64(19), np.int64(1): np.int64(139)} after={np.int64(0): np.int64(19), np.int64(1): np.int64(278)} multiplier=2.0\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_baseline.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_genai.md\n",
      "Wrote section report: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/section_4_2_5.md\n",
      "{\n",
      "  \"run_id\": \"1756984572\",\n",
      "  \"started\": \"2025-09-04 13:16:12\",\n",
      "  \"paper_id\": \"Farzipour_2023\",\n",
      "  \"modality\": \"tabular\",\n",
      "  \"dataset_key\": \"symptom_farzipour\",\n",
      "  \"model\": {\n",
      "    \"name\": \"xgboost\",\n",
      "    \"params\": {\n",
      "      \"n_estimators\": 300,\n",
      "      \"max_depth\": 4,\n",
      "      \"learning_rate\": 0.08\n",
      "    }\n",
      "  },\n",
      "  \"synth\": {\n",
      "    \"enabled\": true,\n",
      "    \"minority_multiplier\": 2.0\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"acc\": 0.8867924528301887,\n",
      "    \"f1\": 0.9387755102040817,\n",
      "    \"f1_ci\": [\n",
      "      0.8842105263157894,\n",
      "      0.9807692307692307\n",
      "    ],\n",
      "    \"threshold\": 0.3710886240005493,\n",
      "    \"f1_tuned\": 0.9494949494949495,\n",
      "    \"f1_tuned_ci\": [\n",
      "      0.8958333333333334,\n",
      "      0.9902912621359223\n",
      "    ]\n",
      "  },\n",
      "  \"tuning\": {\n",
      "    \"tune_enabled\": true,\n",
      "    \"method\": \"grid\",\n",
      "    \"cv\": 5,\n",
      "    \"scoring\": \"f1\",\n",
      "    \"best_params\": {\n",
      "      \"colsample_bytree\": 0.7,\n",
      "      \"learning_rate\": 0.1,\n",
      "      \"max_depth\": 3,\n",
      "      \"min_child_weight\": 1,\n",
      "      \"n_estimators\": 500,\n",
      "      \"subsample\": 0.9\n",
      "    },\n",
      "    \"best_score_cv\": 0.9703413872942429\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from cbe_repro.experiments.run_unified import run_from_profile\n",
    "print(\"=== Farzipour 2023 — BASELINE (tuned) ===\")\n",
    "run_from_profile(\"farzipour_2023_baseline.yaml\")\n",
    "\n",
    "print(\"\\n=== Farzipour 2023 — GenAI (tuned) ===\")\n",
    "run_from_profile(\"farzipour_2023_genai.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c50ef-6ceb-4782-af1c-bd925776b6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c90fb-3c45-403c-a00d-ad906544687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\chadrackm\\OneDrive - University of Johannesburg\\Documents\\MASTER DATA SCIENCE YEAR 2\\LTD SCOPE RESEARCH PROJ APPLIED DATA\\Chapter Four\\Framework\\mpox_repro_framework\\src\\cbe_repro\\data/monkeypox_global_symptoms.csv\")\n",
    "print(df['Status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a84a7-03dc-44dc-a018-ce47452f984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbe_repro.reporting.write_docs import write_experiment_cards, write_section_4_2_5_report\n",
    "write_experiment_cards()\n",
    "write_section_4_2_5_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e6217-3b2b-40a7-b243-f082361223ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f828ba76-5165-4f44-8509-7605b010dc85",
   "metadata": {},
   "source": [
    "## Part to Reload and Re-run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2fcda1b-9364-4940-b7b0-85e95104f2d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cbe_repro'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcbe_repro\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun_unified\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_from_profile\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cbe_repro'"
     ]
    }
   ],
   "source": [
    "from cbe_repro.experiments.run_unified import run_from_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dcb2ba-4d9a-4d97-8343-5ecd4619669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import cbe_repro.experiments.run_unified as run_unified\n",
    "import cbe_repro.reporting.write_docs as write_docs\n",
    "\n",
    "# Reload them\n",
    "importlib.reload(run_unified)\n",
    "importlib.reload(write_docs)\n",
    "\n",
    "# Now import the function again\n",
    "from cbe_repro.experiments.run_unified import run_from_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9543d0c4-0f6a-42ba-93e3-0cffb4f5e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Farzipour 2023 — BASELINE (tuned) ===\n",
      "[DOC] synth_enabled=False, balance_to_max=False, target_ratio=None | train_counts_before={0: 19, 1: 139} -> after={0: 19, 1: 139}\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_baseline.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_genai.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/Farzipour_2023.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/farzipour_2023_baseline.md\n",
      "Wrote section report: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/section_4_2_5.md\n",
      "{\n",
      "  \"run_id\": \"1757015029\",\n",
      "  \"started\": \"2025-09-04 21:43:49\",\n",
      "  \"paper_id\": \"Farzipour_2023\",\n",
      "  \"modality\": \"tabular\",\n",
      "  \"dataset_key\": \"symptom_farzipour\",\n",
      "  \"model\": {\n",
      "    \"name\": \"xgboost\",\n",
      "    \"params\": {\n",
      "      \"n_estimators\": 300,\n",
      "      \"max_depth\": 4,\n",
      "      \"learning_rate\": 0.08\n",
      "    }\n",
      "  },\n",
      "  \"synth\": {\n",
      "    \"enabled\": false,\n",
      "    \"applied\": false\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"acc\": 0.8867924528301887,\n",
      "    \"f1\": 0.9387755102040817,\n",
      "    \"f1_ci\": [\n",
      "      0.8842105263157894,\n",
      "      0.9807692307692307\n",
      "    ],\n",
      "    \"threshold\": 0.39333659410476685,\n",
      "    \"f1_tuned\": 0.9494949494949495,\n",
      "    \"f1_tuned_ci\": [\n",
      "      0.8958333333333334,\n",
      "      0.9902912621359223\n",
      "    ]\n",
      "  },\n",
      "  \"data_snapshot\": {\n",
      "    \"n_features\": 46,\n",
      "    \"label_col\": \"status\",\n",
      "    \"train_counts_before\": {\n",
      "      \"0\": 19,\n",
      "      \"1\": 139\n",
      "    },\n",
      "    \"train_counts_after\": {\n",
      "      \"0\": 19,\n",
      "      \"1\": 139\n",
      "    }\n",
      "  },\n",
      "  \"tuning\": {\n",
      "    \"tune_enabled\": true,\n",
      "    \"method\": \"grid\",\n",
      "    \"cv\": 5,\n",
      "    \"scoring\": \"f1\",\n",
      "    \"best_params\": {\n",
      "      \"colsample_bytree\": 0.7,\n",
      "      \"learning_rate\": 0.05,\n",
      "      \"max_depth\": 3,\n",
      "      \"min_child_weight\": 1,\n",
      "      \"n_estimators\": 500,\n",
      "      \"subsample\": 0.9\n",
      "    },\n",
      "    \"best_score_cv\": 0.9424680344930122\n",
      "  },\n",
      "  \"config_name\": \"farzipour_2023_baseline.yaml\",\n",
      "  \"xai\": {\n",
      "    \"enabled\": false\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Farzipour 2023 — GenAI (tuned) ===\n",
      "[DEBUG] SMOTE balance → before={np.int64(0): np.int64(19), np.int64(1): np.int64(139)} after={np.int64(0): np.int64(112), np.int64(1): np.int64(139)} target_ratio=0.8\n",
      "[DOC] synth_enabled=True, balance_to_max=False, target_ratio=0.8 | train_counts_before={0: 19, 1: 139} -> after={0: 112, 1: 139}\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_baseline.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_genai.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/Farzipour_2023.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/farzipour_2023_baseline.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/farzipour_2023_genai.md\n",
      "Wrote section report: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/section_4_2_5.md\n",
      "{\n",
      "  \"run_id\": \"1757015073\",\n",
      "  \"started\": \"2025-09-04 21:44:33\",\n",
      "  \"paper_id\": \"Farzipour_2023\",\n",
      "  \"modality\": \"tabular\",\n",
      "  \"dataset_key\": \"symptom_farzipour\",\n",
      "  \"model\": {\n",
      "    \"name\": \"xgboost\",\n",
      "    \"params\": {\n",
      "      \"n_estimators\": 300,\n",
      "      \"max_depth\": 4,\n",
      "      \"learning_rate\": 0.08\n",
      "    }\n",
      "  },\n",
      "  \"synth\": {\n",
      "    \"enabled\": true,\n",
      "    \"minority_multiplier\": 2.0,\n",
      "    \"target_ratio\": 0.8,\n",
      "    \"applied\": true\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"acc\": 0.7735849056603774,\n",
      "    \"f1\": 0.8666666666666667,\n",
      "    \"f1_ci\": [\n",
      "      0.7847301033027789,\n",
      "      0.937531887755102\n",
      "    ],\n",
      "    \"threshold\": 0.19904989004135132,\n",
      "    \"f1_tuned\": 0.9494949494949495,\n",
      "    \"f1_tuned_ci\": [\n",
      "      0.8958333333333334,\n",
      "      0.9902912621359223\n",
      "    ]\n",
      "  },\n",
      "  \"data_snapshot\": {\n",
      "    \"n_features\": 46,\n",
      "    \"label_col\": \"status\",\n",
      "    \"train_counts_before\": {\n",
      "      \"0\": 19,\n",
      "      \"1\": 139\n",
      "    },\n",
      "    \"train_counts_after\": {\n",
      "      \"0\": 112,\n",
      "      \"1\": 139\n",
      "    }\n",
      "  },\n",
      "  \"tuning\": {\n",
      "    \"tune_enabled\": true,\n",
      "    \"method\": \"grid\",\n",
      "    \"cv\": 5,\n",
      "    \"scoring\": \"f1\",\n",
      "    \"best_params\": {\n",
      "      \"colsample_bytree\": 0.7,\n",
      "      \"learning_rate\": 0.08,\n",
      "      \"max_depth\": 4,\n",
      "      \"min_child_weight\": 1,\n",
      "      \"n_estimators\": 300,\n",
      "      \"subsample\": 0.9\n",
      "    },\n",
      "    \"best_score_cv\": 0.8436412216878365\n",
      "  },\n",
      "  \"config_name\": \"farzipour_2023_genai.yaml\",\n",
      "  \"xai\": {\n",
      "    \"enabled\": false\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Farzipour 2023 — BASELINE (tuned) ===\")\n",
    "run_from_profile(\"farzipour_2023_baseline.yaml\")\n",
    "\n",
    "print(\"\\n=== Farzipour 2023 — GenAI (tuned) ===\")\n",
    "run_from_profile(\"farzipour_2023_genai.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ffa7e-4d70-498e-a846-3fd95c10d068",
   "metadata": {},
   "source": [
    "## Images Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "70c96ed1-fada-4c78-96ab-4799a37e04d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cbe_repro.synth.image_loader' from '/Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/synth/image_loader.py'>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cbe_repro.synth.image_loader as image_loader\n",
    "importlib.reload(image_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d32762e1-9bdb-469f-90af-5ccabf7d3f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbe_repro.experiments.run_unified import run_from_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8a9a2bfd-2b9c-40e6-854d-e225b8090c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import cbe_repro.experiments.run_unified as run_unified\n",
    "import cbe_repro.reporting.write_docs as write_docs\n",
    "\n",
    "# Reload them\n",
    "importlib.reload(run_unified)\n",
    "importlib.reload(write_docs)\n",
    "\n",
    "# Now import the function again\n",
    "from cbe_repro.experiments.run_unified import run_from_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "13fc957d-8bfb-40ae-8d11-0645fbdc293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Imaging — BASELINE ===\n",
      "[DOC][IMG] synth_enabled=False, balance_to_max=False, target_ratio=None | before={0: 100, 1: 81} -> after={0: 100, 1: 81}\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_genai.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/Farzipour_2023.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/farzipour_2023_baseline.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/farzipour_2023_genai.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_baseline.md\n",
      "Wrote section report: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/section_4_2_5.md\n",
      "{\n",
      "  \"run_id\": \"1757023903\",\n",
      "  \"started\": \"2025-09-05 00:11:43\",\n",
      "  \"paper_id\": \"test\",\n",
      "  \"modality\": \"imaging\",\n",
      "  \"dataset_key\": \"mpox_images\",\n",
      "  \"model\": {\n",
      "    \"name\": \"logisticregression\",\n",
      "    \"params\": {\n",
      "      \"max_iter\": 200,\n",
      "      \"n_jobs\": -1\n",
      "    }\n",
      "  },\n",
      "  \"synth\": {\n",
      "    \"enabled\": false,\n",
      "    \"applied\": false\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"acc\": 0.5957446808510638,\n",
      "    \"f1\": 0.5777777777777777,\n",
      "    \"f1_ci\": [\n",
      "      0.3902439024390244,\n",
      "      0.7408496732026142\n",
      "    ],\n",
      "    \"threshold\": 0.004560169731889629,\n",
      "    \"f1_tuned\": 0.6363636363636364,\n",
      "    \"f1_tuned_ci\": [\n",
      "      0.4838709677419355,\n",
      "      0.7671232876712328\n",
      "    ]\n",
      "  },\n",
      "  \"data_snapshot\": {\n",
      "    \"n_images_train\": 181,\n",
      "    \"n_images_val\": 47,\n",
      "    \"img_size\": 128,\n",
      "    \"train_counts_before\": {\n",
      "      \"0\": 100,\n",
      "      \"1\": 81\n",
      "    },\n",
      "    \"train_counts_after\": {\n",
      "      \"0\": 100,\n",
      "      \"1\": 81\n",
      "    }\n",
      "  },\n",
      "  \"tuning\": {\n",
      "    \"tune_enabled\": false\n",
      "  },\n",
      "  \"config_name\": \"imaging_baseline.yaml\",\n",
      "  \"xai\": {\n",
      "    \"enabled\": false\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Imaging — GenAI ===\n",
      "[IMG] counts before synth: {np.int64(0): np.int64(100), np.int64(1): np.int64(81)}\n",
      "[IMG] balancing → ratio=1.0 before={np.int64(0): np.int64(100), np.int64(1): np.int64(81)} after={np.int64(0): np.int64(100), np.int64(1): np.int64(100)}\n",
      "[DOC][IMG] synth_enabled=True, balance_to_max=True, target_ratio=None | before={0: 100, 1: 81} -> after={0: 100, 1: 100}\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/Farzipour_2023.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/farzipour_2023_baseline.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/farzipour_2023_genai.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_baseline.md\n",
      "Wrote card: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/cards/imaging_genai.md\n",
      "Wrote section report: /Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/reports/section_4_2_5.md\n",
      "{\n",
      "  \"run_id\": \"1757023906\",\n",
      "  \"started\": \"2025-09-05 00:11:46\",\n",
      "  \"paper_id\": \"test\",\n",
      "  \"modality\": \"imaging\",\n",
      "  \"dataset_key\": \"mpox_images\",\n",
      "  \"model\": {\n",
      "    \"name\": \"logisticregression\",\n",
      "    \"params\": {\n",
      "      \"max_iter\": 200,\n",
      "      \"n_jobs\": -1\n",
      "    }\n",
      "  },\n",
      "  \"synth\": {\n",
      "    \"enabled\": true,\n",
      "    \"balance_to_max\": true,\n",
      "    \"applied\": true\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"acc\": 0.6170212765957447,\n",
      "    \"f1\": 0.6086956521739131,\n",
      "    \"f1_ci\": [\n",
      "      0.42416267942583735,\n",
      "      0.7692307692307693\n",
      "    ],\n",
      "    \"threshold\": 0.0056555600720827005,\n",
      "    \"f1_tuned\": 0.6268656716417911,\n",
      "    \"f1_tuned_ci\": [\n",
      "      0.4838709677419355,\n",
      "      0.7567567567567568\n",
      "    ]\n",
      "  },\n",
      "  \"data_snapshot\": {\n",
      "    \"n_images_train\": 181,\n",
      "    \"n_images_val\": 47,\n",
      "    \"img_size\": 128,\n",
      "    \"train_counts_before\": {\n",
      "      \"0\": 100,\n",
      "      \"1\": 81\n",
      "    },\n",
      "    \"train_counts_after\": {\n",
      "      \"0\": 100,\n",
      "      \"1\": 100\n",
      "    }\n",
      "  },\n",
      "  \"tuning\": {\n",
      "    \"tune_enabled\": false\n",
      "  },\n",
      "  \"config_name\": \"imaging_genai.yaml\",\n",
      "  \"xai\": {\n",
      "    \"enabled\": false\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from cbe_repro.experiments.run_unified import run_from_profile\n",
    "\n",
    "print(\"=== Imaging — BASELINE ===\")\n",
    "run_from_profile(\"imaging_baseline.yaml\")\n",
    "\n",
    "print(\"\\n=== Imaging — GenAI ===\")\n",
    "run_from_profile(\"imaging_genai.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "995d78cc-17d2-4f1b-93c2-c8264e2fad20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/synth/image_loader.py\n",
      "(self, synth_enabled: 'bool' = False, synth_multiplier: 'float' = 2.0, balance_to_max: 'bool' = False, target_ratio: 'Optional[float]' = None, seed: 'int' = 1337, synth_verbose: 'bool' = True)\n"
     ]
    }
   ],
   "source": [
    "import importlib, cbe_repro.synth.image_loader as il\n",
    "import inspect\n",
    "print(il.__file__)  # confirm it points to your edited file\n",
    "importlib.reload(il)\n",
    "\n",
    "# verify the signature really includes the new args\n",
    "print(inspect.signature(il.ImageFolderDataset.as_features_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7df5f4-1105-4881-90c5-f9cf66d83ec6",
   "metadata": {},
   "source": [
    "### VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beba788-a704-4fec-bb99-b06757d04799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbe_repro.experiments.run_unified import run_from_profile\n",
    "\n",
    "print(\"=== ViT Baseline (Ayana-style) ===\")\n",
    "run_from_profile(\"imaging_vit_baseline.yaml\")\n",
    "\n",
    "print(\"\\n=== ViT + Balanced Sampler (GenAI) ===\")\n",
    "run_from_profile(\"imaging_vit_genai.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8198181-7dc5-4123-a4ad-5a2a763b17fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1 0.22.0 1.0.19\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision, timm\n",
    "print(torch.__version__, torchvision.__version__, timm.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ab50511-dd20-4197-a7c0-502dbc98516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.expanduser(\"~/Downloads/Master Code/Framework/mpox_repro_framework/src\"))\n",
    "\n",
    "# sanity check\n",
    "import cbe_repro\n",
    "from cbe_repro.experiments.run_unified import run_from_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f63b93-e260-4a73-abf2-b034434712b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import cbe_repro.experiments.run_unified as run_unified\n",
    "import cbe_repro.reporting.write_docs as write_docs\n",
    "\n",
    "# Reload them\n",
    "importlib.reload(run_unified)\n",
    "importlib.reload(write_docs)\n",
    "\n",
    "# Now import the function again\n",
    "from cbe_repro.experiments.run_unified import run_from_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab646b9-637b-4d1e-a0c2-303301773605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ViT Baseline (Ayana-style) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/run_unified.py:123: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=amp and device.type == \"cuda\")\n",
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/munashemanzira/Downloads/Master Code/Framework/mpox_repro_framework/src/cbe_repro/experiments/run_unified.py:136: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=amp and device.type==\"cuda\"):\n"
     ]
    }
   ],
   "source": [
    "from cbe_repro.experiments.run_unified import run_from_profile\n",
    "\n",
    "print(\"=== ViT Baseline (Ayana-style) ===\")\n",
    "run_from_profile(\"imaging_vit_baseline.yaml\")\n",
    "\n",
    "print(\"\\n=== ViT + Balanced Sampler (GenAI) ===\")\n",
    "run_from_profile(\"imaging_vit_genai.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e786f-2d92-4f1b-9891-446bb16a1da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
